#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
CandlesDB Writer
PostgreSQLì— ìº”ë“¤ ë°ì´í„° ì €ì¥ (dual-write with Redis)
"""

import logging
import os
import time
from datetime import datetime, timezone
from decimal import Decimal
from typing import Any

import psycopg2
from psycopg2.extras import execute_values
from psycopg2.pool import SimpleConnectionPool

from shared.logging import get_logger

logger = get_logger(__name__)


class CandlesDBWriter:
    """CandlesDB PostgreSQL Writer with connection pooling"""

    def __init__(self):
        """Initialize connection pool"""
        self.pool: SimpleConnectionPool | None = None
        self.enabled = False

        # ëª¨ë‹ˆí„°ë§ ì¹´ìš´í„°
        self.success_count = 0
        self.failure_count = 0
        self.last_failure_time: float | None = None
        self.last_health_check: float = 0

        # ì„¤ì •
        self.max_retries = 3
        self.retry_delay_base = 1  # ì´ˆ
        self.health_check_interval = 60  # 60ì´ˆë§ˆë‹¤ health check

        self._init_pool()

    def _init_pool(self):
        """Initialize PostgreSQL connection pool"""
        try:
            # Get config from environment variables directly
            candles_host = os.getenv("CANDLES_HOST", "158.247.251.34")
            candles_port = int(os.getenv("CANDLES_PORT", "5432"))
            candles_db = os.getenv("CANDLES_DATABASE", "candlesdb")
            candles_user = os.getenv("CANDLES_USER", "tradeuser")
            candles_password = os.getenv("CANDLES_PASSWORD", "SecurePassword123")

            self.pool = SimpleConnectionPool(
                minconn=1,
                maxconn=10,
                host=candles_host,
                port=candles_port,
                database=candles_db,
                user=candles_user,
                password=candles_password,
            )
            self.enabled = True
            logger.info(
                f"âœ… CandlesDB connection pool initialized: {candles_host}:{candles_port}/{candles_db}"
            )
        except Exception as e:
            logger.error(f"âŒ Failed to initialize CandlesDB pool: {e}")
            self.enabled = False

    def get_connection(self):
        """Get connection from pool"""
        if not self.pool:
            raise Exception("Connection pool not initialized")
        return self.pool.getconn()

    def put_connection(self, conn):
        """Return connection to pool"""
        if self.pool:
            self.pool.putconn(conn)

    def close_pool(self):
        """Close all connections in pool"""
        if self.pool:
            self.pool.closeall()
            logger.info("CandlesDB connection pool closed")

    def health_check(self) -> bool:
        """
        DB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ìë™ ë³µêµ¬

        Returns:
            True if healthy, False otherwise
        """
        now = time.time()

        # ë„ˆë¬´ ìì£¼ ì²´í¬í•˜ì§€ ì•Šë„ë¡ throttling
        if now - self.last_health_check < self.health_check_interval:
            return self.enabled

        self.last_health_check = now

        # ì´ë¯¸ í™œì„±í™”ëœ ê²½ìš° ê°„ë‹¨í•œ ping í…ŒìŠ¤íŠ¸
        if self.enabled and self.pool:
            try:
                conn = self.get_connection()
                cur = conn.cursor()
                cur.execute("SELECT 1;")
                cur.close()
                self.put_connection(conn)
                logger.debug("âœ… CandlesDB health check: OK")
                return True
            except Exception as e:
                logger.warning(f"âš ï¸ CandlesDB health check failed: {e}")
                self.enabled = False
                # Fall through to reconnect attempt

        # ë¹„í™œì„±í™”ëœ ê²½ìš° ì¬ì—°ê²° ì‹œë„
        if not self.enabled:
            logger.info("ğŸ”„ Attempting to reconnect to CandlesDB...")
            return self.reconnect()

        return False

    def reconnect(self) -> bool:
        """
        CandlesDB ì¬ì—°ê²° ì‹œë„

        Returns:
            True if reconnection successful, False otherwise
        """
        try:
            # ê¸°ì¡´ poolì´ ìˆìœ¼ë©´ ë‹«ê¸°
            if self.pool:
                try:
                    self.pool.closeall()
                except Exception:
                    pass
                self.pool = None

            # ìƒˆë¡œìš´ pool ì´ˆê¸°í™”
            self._init_pool()

            if self.enabled:
                logger.info("âœ… CandlesDB reconnection successful!")
                return True
            else:
                logger.warning("âŒ CandlesDB reconnection failed")
                return False

        except Exception as e:
            logger.error(f"âŒ CandlesDB reconnection error: {e}")
            self.enabled = False
            return False

    def _retry_operation(self, operation, *args, **kwargs):
        """
        Retry operation with exponential backoff

        Args:
            operation: Function to retry
            *args, **kwargs: Arguments for the operation

        Returns:
            Operation result or None if all retries failed
        """
        for attempt in range(self.max_retries):
            try:
                result = operation(*args, **kwargs)
                if attempt > 0:
                    logger.info(f"âœ… Retry successful on attempt {attempt + 1}")
                return result

            except psycopg2.OperationalError as e:
                # ì—°ê²° ê´€ë ¨ ì˜¤ë¥˜ - ì¬ì‹œë„ ê°€ëŠ¥
                if attempt < self.max_retries - 1:
                    delay = self.retry_delay_base * (2 ** attempt)  # Exponential backoff
                    logger.warning(
                        f"âš ï¸ DB operation failed (attempt {attempt + 1}/{self.max_retries}), "
                        f"retrying in {delay}s: {e}"
                    )
                    time.sleep(delay)
                else:
                    logger.error(f"âŒ DB operation failed after {self.max_retries} attempts: {e}")
                    raise

            except Exception as e:
                # ë‹¤ë¥¸ ì˜¤ë¥˜ - ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                logger.error(f"âŒ DB operation error (non-retryable): {e}")
                raise

        return None

    @staticmethod
    def normalize_symbol(okx_symbol: str) -> str:
        """
        OKX ì‹¬ë³¼ í˜•ì‹ì„ CandlesDB í…Œì´ë¸”ëª…ìœ¼ë¡œ ë³€í™˜

        Examples:
            BTC-USDT-SWAP â†’ btc_usdt
            ETH-USDT-SWAP â†’ eth_usdt
            SOL-USDT-SWAP â†’ sol_usdt
        """
        # Remove -SWAP suffix and convert to lowercase
        parts = okx_symbol.replace("-SWAP", "").split("-")
        return "_".join(parts).lower()

    @staticmethod
    def convert_timeframe(minutes: int) -> str:
        """
        ë¶„ ë‹¨ìœ„ timeframeì„ ë¬¸ìì—´ë¡œ ë³€í™˜

        Examples:
            1 â†’ "1m"
            3 â†’ "3m"
            5 â†’ "5m"
            15 â†’ "15m"
            30 â†’ "30m"
            60 â†’ "1h"
            240 â†’ "4h"
        """
        if minutes < 60:
            return f"{minutes}m"
        elif minutes == 60:
            return "1h"
        elif minutes == 240:
            return "4h"
        elif minutes == 1440:
            return "1d"
        else:
            # Fallback for other timeframes
            hours = minutes // 60
            return f"{hours}h"

    @staticmethod
    def convert_candle_to_db_row(candle: dict[str, Any], timeframe_str: str) -> tuple:
        """
        Redis ìº”ë“¤ ë°ì´í„°ë¥¼ DB rowë¡œ ë³€í™˜

        Args:
            candle: Redis candle dict
            timeframe_str: Timeframe string (e.g., "1m", "1h")

        Returns:
            Tuple of values for DB insert
        """
        # timestamp (ì´ˆ) â†’ PostgreSQL timestamptz
        ts = candle["timestamp"]
        time = datetime.fromtimestamp(ts, tz=timezone.utc)

        # Convert to Decimal for precision
        return (
            time,
            timeframe_str,
            Decimal(str(candle["open"])),
            Decimal(str(candle["high"])),
            Decimal(str(candle["low"])),
            Decimal(str(candle["close"])),
            Decimal(str(candle["volume"])),
            Decimal(str(candle.get("rsi", 0))) if candle.get("rsi") else None,  # rsi14
            Decimal(str(candle.get("atr14", 0))) if candle.get("atr14") else None,  # atr
            Decimal(str(candle.get("ema7", 0))) if candle.get("ema7") else None,  # ema7
            Decimal(str(candle.get("sma20", 0))) if candle.get("sma20") else None,  # ma20
            int(candle.get("trend_state", 0)) if candle.get("trend_state") is not None else None,  # trend_state
            int(candle.get("auto_trend_state", 0)) if candle.get("auto_trend_state") is not None else None,  # auto_trend_state
        )

    def _do_upsert(self, table_name: str, timeframe_str: str, rows: list[tuple]) -> bool:
        """
        ì‹¤ì œ upsert ì‘ì—… ìˆ˜í–‰ (retry ê°€ëŠ¥)

        Args:
            table_name: Table name
            timeframe_str: Timeframe string
            rows: Rows to upsert

        Returns:
            Success flag
        """
        conn = None
        try:
            conn = self.get_connection()
            cur = conn.cursor()

            # Upsert query with ON CONFLICT UPDATE
            upsert_query = f"""
                INSERT INTO {table_name} (
                    time, timeframe, open, high, low, close, volume,
                    rsi14, atr, ema7, ma20, trend_state, auto_trend_state
                )
                VALUES %s
                ON CONFLICT (time, timeframe)
                DO UPDATE SET
                    open = EXCLUDED.open,
                    high = EXCLUDED.high,
                    low = EXCLUDED.low,
                    close = EXCLUDED.close,
                    volume = EXCLUDED.volume,
                    rsi14 = EXCLUDED.rsi14,
                    atr = EXCLUDED.atr,
                    ema7 = EXCLUDED.ema7,
                    ma20 = EXCLUDED.ma20,
                    trend_state = EXCLUDED.trend_state,
                    auto_trend_state = EXCLUDED.auto_trend_state;
            """

            # Execute batch upsert
            execute_values(cur, upsert_query, rows)
            conn.commit()

            logger.debug(
                f"âœ… CandlesDB upsert: {table_name} ({timeframe_str}) - {len(rows)} candles"
            )
            return True

        except Exception as e:
            if conn:
                conn.rollback()
            raise  # Re-raise for retry logic

        finally:
            if conn:
                cur.close()
                self.put_connection(conn)

    def upsert_candles(
        self, symbol: str, timeframe_minutes: int, candles: list[dict[str, Any]]
    ) -> bool:
        """
        ìº”ë“¤ ë°ì´í„°ë¥¼ DBì— upsert (insert or update) with retry

        Args:
            symbol: OKX symbol (e.g., "BTC-USDT-SWAP")
            timeframe_minutes: Timeframe in minutes
            candles: List of candle dicts

        Returns:
            Success flag
        """
        if not self.enabled or not candles:
            return False

        table_name = self.normalize_symbol(symbol)
        timeframe_str = self.convert_timeframe(timeframe_minutes)

        try:
            # Prepare rows for batch insert
            rows = []
            for candle in candles:
                try:
                    row = self.convert_candle_to_db_row(candle, timeframe_str)
                    rows.append(row)
                except Exception as e:
                    logger.warning(f"Failed to convert candle: {candle} - {e}")
                    continue

            if not rows:
                logger.warning(f"No valid rows to insert for {table_name}")
                return False

            # Retry upsert operation with exponential backoff
            self._retry_operation(self._do_upsert, table_name, timeframe_str, rows)

            # ì„±ê³µ ì¹´ìš´í„° ì¦ê°€
            self.success_count += len(rows)
            logger.info(
                f"âœ… CandlesDB upsert: {table_name} ({timeframe_str}) - {len(rows)} candles "
                f"(success: {self.success_count}, failures: {self.failure_count})"
            )
            return True

        except Exception as e:
            # ì‹¤íŒ¨ ì¹´ìš´í„° ì¦ê°€
            self.failure_count += len(candles)
            self.last_failure_time = time.time()

            logger.error(
                f"âŒ CandlesDB upsert failed: {table_name} ({timeframe_str}) - {e} "
                f"(success: {self.success_count}, failures: {self.failure_count})"
            )
            return False

    def upsert_single_candle(
        self, symbol: str, timeframe_minutes: int, candle: dict[str, Any]
    ) -> bool:
        """
        ë‹¨ì¼ ìº”ë“¤ upsert (wrapper)

        Args:
            symbol: OKX symbol
            timeframe_minutes: Timeframe in minutes
            candle: Single candle dict

        Returns:
            Success flag
        """
        return self.upsert_candles(symbol, timeframe_minutes, [candle])

    def get_stats(self) -> dict[str, Any]:
        """
        ëª¨ë‹ˆí„°ë§ í†µê³„ ë°˜í™˜

        Returns:
            Dictionary with monitoring stats
        """
        stats = {
            "enabled": self.enabled,
            "success_count": self.success_count,
            "failure_count": self.failure_count,
            "total_count": self.success_count + self.failure_count,
            "success_rate": (
                self.success_count / (self.success_count + self.failure_count) * 100
                if (self.success_count + self.failure_count) > 0
                else 0.0
            ),
            "last_failure_time": self.last_failure_time,
            "last_health_check": self.last_health_check,
        }
        return stats

    def log_stats(self):
        """í†µê³„ ë¡œê·¸ ì¶œë ¥"""
        stats = self.get_stats()
        logger.info(
            f"ğŸ“Š CandlesDB Stats: "
            f"enabled={stats['enabled']}, "
            f"success={stats['success_count']}, "
            f"failure={stats['failure_count']}, "
            f"rate={stats['success_rate']:.1f}%"
        )


# Singleton instance
_candlesdb_writer: CandlesDBWriter | None = None


def get_candlesdb_writer() -> CandlesDBWriter:
    """Get singleton CandlesDB writer instance"""
    global _candlesdb_writer
    if _candlesdb_writer is None:
        _candlesdb_writer = CandlesDBWriter()
    return _candlesdb_writer


# Cleanup on module exit
import atexit


def cleanup_candlesdb():
    """Cleanup CandlesDB connections on exit"""
    global _candlesdb_writer
    if _candlesdb_writer:
        _candlesdb_writer.close_pool()


atexit.register(cleanup_candlesdb)
