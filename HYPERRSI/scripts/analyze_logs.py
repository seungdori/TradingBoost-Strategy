#!/usr/bin/env python3
"""
ë¡œê·¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì£¼ë¬¸ ë¡œê·¸, ì—ëŸ¬ ë¡œê·¸, ì•Œë¦¼ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ í†µê³„ì™€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import json
import sys
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Tuple
import argparse


class LogAnalyzer:
    """ë¡œê·¸ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, log_dir: Path):
        self.log_dir = log_dir
        self.orders_dir = log_dir / 'orders'
        self.errors_dir = log_dir / 'errors'
        self.alerts_dir = log_dir / 'alerts'
        self.debug_dir = log_dir / 'debug'

    def analyze_order_logs(self, days: int = 7) -> Dict[str, Any]:
        """
        ì£¼ë¬¸ ë¡œê·¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

        Args:
            days: ë¶„ì„í•  ê¸°ê°„ (ì¼)

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        action_types = Counter()
        symbols = Counter()
        users = Counter()
        position_sides = Counter()
        total_volume = 0.0
        errors = []
        hourly_distribution = defaultdict(int)

        order_log_file = self.orders_dir / 'trading_orders.log'

        if not order_log_file.exists():
            print(f"âš ï¸  ì£¼ë¬¸ ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {order_log_file}")
            return {}

        with open(order_log_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    log_entry = json.loads(line)
                    log_time = datetime.fromisoformat(log_entry.get('timestamp', ''))

                    if log_time >= cutoff_date:
                        action_types[log_entry.get('action_type', 'unknown')] += 1
                        symbols[log_entry.get('symbol', 'unknown')] += 1
                        users[log_entry.get('user_id', 'unknown')] += 1
                        position_sides[log_entry.get('position_side', 'unknown')] += 1

                        # ì‹œê°„ëŒ€ë³„ ë¶„í¬
                        hour = log_time.hour
                        hourly_distribution[hour] += 1

                        # ê±°ë˜ëŸ‰ ê³„ì‚°
                        if 'quantity' in log_entry and log_entry['quantity']:
                            try:
                                total_volume += float(log_entry['quantity'])
                            except (ValueError, TypeError):
                                pass

                        # ì—ëŸ¬ ë¡œê·¸ ìˆ˜ì§‘
                        if log_entry.get('level') == 'ERROR':
                            errors.append(log_entry)

                except (json.JSONDecodeError, ValueError, KeyError) as e:
                    continue

        return {
            'total_orders': sum(action_types.values()),
            'action_types': dict(action_types.most_common(10)),
            'top_symbols': dict(symbols.most_common(10)),
            'active_users': len(users),
            'top_users': dict(users.most_common(5)),
            'position_distribution': dict(position_sides),
            'total_volume': round(total_volume, 4),
            'error_count': len(errors),
            'hourly_distribution': dict(sorted(hourly_distribution.items())),
            'errors': errors[:10]  # ìµœê·¼ 10ê°œ ì—ëŸ¬
        }

    def analyze_error_logs(self, days: int = 7) -> Dict[str, Any]:
        """
        ì—ëŸ¬ ë¡œê·¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

        Args:
            days: ë¶„ì„í•  ê¸°ê°„ (ì¼)

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        error_types = Counter()
        error_modules = Counter()
        critical_errors = []
        recent_errors = []

        error_log_file = self.errors_dir / 'error.log'

        if not error_log_file.exists():
            print(f"âš ï¸  ì—ëŸ¬ ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {error_log_file}")
            return {}

        with open(error_log_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    # ë¡œê·¸ ë¼ì¸ íŒŒì‹± (ê°„ë‹¨í•œ í˜•ì‹ ê°€ì •)
                    if 'ERROR' in line or 'CRITICAL' in line:
                        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ ì‹œë„
                        parts = line.split(' - ')
                        if len(parts) >= 2:
                            try:
                                timestamp_str = parts[0].strip('[]')
                                log_time = datetime.fromisoformat(timestamp_str)

                                if log_time >= cutoff_date:
                                    if 'CRITICAL' in line:
                                        critical_errors.append(line.strip())
                                        error_types['CRITICAL'] += 1
                                    elif 'ERROR' in line:
                                        error_types['ERROR'] += 1
                                        recent_errors.append(line.strip())

                                    # ëª¨ë“ˆëª… ì¶”ì¶œ
                                    if len(parts) >= 3:
                                        module = parts[1].strip()
                                        error_modules[module] += 1
                            except (ValueError, IndexError):
                                continue
                except Exception:
                    continue

        return {
            'total_errors': sum(error_types.values()),
            'error_distribution': dict(error_types),
            'top_error_modules': dict(error_modules.most_common(10)),
            'critical_errors': critical_errors[:5],
            'recent_errors': recent_errors[:10]
        }

    def analyze_alert_logs(self, days: int = 7) -> Dict[str, Any]:
        """
        ì•Œë¦¼ ë¡œê·¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

        Args:
            days: ë¶„ì„í•  ê¸°ê°„ (ì¼)

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        alert_types = Counter()
        user_alerts = Counter()
        symbol_alerts = Counter()

        # ìµœê·¼ Nì¼ê°„ì˜ ì•Œë¦¼ ë¡œê·¸ íŒŒì¼ ì°¾ê¸°
        alert_files = []
        for i in range(days + 1):
            date_str = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
            alert_file = self.alerts_dir / f'system_alerts_{date_str}.log'
            if alert_file.exists():
                alert_files.append(alert_file)

        total_alerts = 0
        for alert_file in alert_files:
            with open(alert_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        log_entry = json.loads(line)
                        alert_types[log_entry.get('alert_type', 'unknown')] += 1
                        user_alerts[log_entry.get('user_id', 'unknown')] += 1
                        symbol_alerts[log_entry.get('symbol', 'unknown')] += 1
                        total_alerts += 1
                    except (json.JSONDecodeError, KeyError):
                        continue

        return {
            'total_alerts': total_alerts,
            'alert_types': dict(alert_types.most_common(10)),
            'top_user_alerts': dict(user_alerts.most_common(5)),
            'top_symbol_alerts': dict(symbol_alerts.most_common(5))
        }

    def print_report(self, days: int = 7):
        """
        ì „ì²´ ë¡œê·¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

        Args:
            days: ë¶„ì„í•  ê¸°ê°„ (ì¼)
        """
        print("=" * 80)
        print(f"ğŸ“Š  HYPERRSI ë¡œê·¸ ë¶„ì„ ë¦¬í¬íŠ¸ (ìµœê·¼ {days}ì¼)")
        print("=" * 80)
        print()

        # 1. ì£¼ë¬¸ ë¡œê·¸ ë¶„ì„
        print("ğŸ“¦ [1] ì£¼ë¬¸ ë¡œê·¸ ë¶„ì„")
        print("-" * 80)
        order_stats = self.analyze_order_logs(days)
        if order_stats:
            print(f"ì´ ì£¼ë¬¸ ìˆ˜: {order_stats['total_orders']:,}")
            print(f"í™œì„± ì‚¬ìš©ì: {order_stats['active_users']}")
            print(f"ì´ ê±°ë˜ëŸ‰: {order_stats['total_volume']:,}")
            print(f"ì—ëŸ¬ ìˆ˜: {order_stats['error_count']}")
            print()

            print("ì£¼ë¬¸ íƒ€ì…ë³„ ë¶„í¬:")
            for action_type, count in order_stats['action_types'].items():
                percentage = (count / order_stats['total_orders']) * 100
                print(f"  {action_type:15s}: {count:6,} ({percentage:5.1f}%)")
            print()

            print("ìƒìœ„ ê±°ë˜ ì‹¬ë³¼:")
            for symbol, count in order_stats['top_symbols'].items():
                percentage = (count / order_stats['total_orders']) * 100
                print(f"  {symbol:15s}: {count:6,} ({percentage:5.1f}%)")
            print()

            print("í¬ì§€ì…˜ ë¶„í¬:")
            for position_side, count in order_stats['position_distribution'].items():
                percentage = (count / order_stats['total_orders']) * 100
                print(f"  {position_side:15s}: {count:6,} ({percentage:5.1f}%)")
            print()

            if order_stats['hourly_distribution']:
                print("ì‹œê°„ëŒ€ë³„ ì£¼ë¬¸ ë¶„í¬ (UTC):")
                max_count = max(order_stats['hourly_distribution'].values())
                for hour in range(24):
                    count = order_stats['hourly_distribution'].get(hour, 0)
                    bar_length = int((count / max_count) * 40) if max_count > 0 else 0
                    bar = 'â–ˆ' * bar_length
                    print(f"  {hour:02d}:00  {count:4d}  {bar}")
                print()
        else:
            print("âš ï¸  ë¶„ì„í•  ì£¼ë¬¸ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print()

        # 2. ì—ëŸ¬ ë¡œê·¸ ë¶„ì„
        print("ğŸš¨ [2] ì—ëŸ¬ ë¡œê·¸ ë¶„ì„")
        print("-" * 80)
        error_stats = self.analyze_error_logs(days)
        if error_stats:
            print(f"ì´ ì—ëŸ¬ ìˆ˜: {error_stats['total_errors']:,}")
            print()

            print("ì—ëŸ¬ ë ˆë²¨ ë¶„í¬:")
            for error_type, count in error_stats['error_distribution'].items():
                print(f"  {error_type:15s}: {count:6,}")
            print()

            print("ìƒìœ„ ì—ëŸ¬ ëª¨ë“ˆ:")
            for module, count in error_stats['top_error_modules'].items():
                print(f"  {module:40s}: {count:6,}")
            print()

            if error_stats['critical_errors']:
                print("âš ï¸  ìµœê·¼ ì¹˜ëª…ì  ì—ëŸ¬:")
                for error in error_stats['critical_errors']:
                    print(f"  - {error[:100]}...")
                print()
        else:
            print("âœ… ë¶„ì„í•  ì—ëŸ¬ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print()

        # 3. ì•Œë¦¼ ë¡œê·¸ ë¶„ì„
        print("ğŸ“¢ [3] ì•Œë¦¼ ë¡œê·¸ ë¶„ì„")
        print("-" * 80)
        alert_stats = self.analyze_alert_logs(days)
        if alert_stats:
            print(f"ì´ ì•Œë¦¼ ìˆ˜: {alert_stats['total_alerts']:,}")
            print()

            print("ì•Œë¦¼ íƒ€ì…ë³„ ë¶„í¬:")
            for alert_type, count in alert_stats['alert_types'].items():
                percentage = (count / alert_stats['total_alerts']) * 100
                print(f"  {alert_type:20s}: {count:6,} ({percentage:5.1f}%)")
            print()

            print("ìƒìœ„ ì•Œë¦¼ ë°œìƒ ì‚¬ìš©ì:")
            for user_id, count in alert_stats['top_user_alerts'].items():
                print(f"  {user_id:40s}: {count:6,}")
            print()
        else:
            print("âš ï¸  ë¶„ì„í•  ì•Œë¦¼ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print()

        print("=" * 80)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        print("=" * 80)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='HYPERRSI ë¡œê·¸ ë¶„ì„ ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
    %(prog)s                # ìµœê·¼ 7ì¼ ë¡œê·¸ ë¶„ì„
    %(prog)s -d 30          # ìµœê·¼ 30ì¼ ë¡œê·¸ ë¶„ì„
    %(prog)s -d 1 -v        # ì–´ì œ ë¡œê·¸ë§Œ ìƒì„¸ ë¶„ì„
        """
    )
    parser.add_argument(
        '-d', '--days',
        type=int,
        default=7,
        help='ë¶„ì„í•  ê¸°ê°„ (ì¼) (ê¸°ë³¸ê°’: 7)'
    )
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='ìƒì„¸ ì •ë³´ ì¶œë ¥'
    )

    args = parser.parse_args()

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
    script_dir = Path(__file__).parent
    project_dir = script_dir.parent
    log_dir = project_dir / 'logs'

    if not log_dir.exists():
        print(f"âŒ ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {log_dir}")
        sys.exit(1)

    # ë¡œê·¸ ë¶„ì„ ì‹¤í–‰
    analyzer = LogAnalyzer(log_dir)
    analyzer.print_report(days=args.days)


if __name__ == '__main__':
    main()
