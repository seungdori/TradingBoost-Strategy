"""
ìº”ë“¤ ë°ì´í„° ê´€ë¦¬ API

CandlesDB(PostgreSQL)ì™€ Redisì— ì €ì¥ëœ ìº”ë“¤ ë°ì´í„°ì˜ ì§€í‘œë¥¼ ì¬ê³„ì‚°í•˜ëŠ” APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""
import json
from datetime import datetime, timezone
from decimal import Decimal
from typing import List, Optional, Any

import psycopg2
from psycopg2.extras import execute_values
import pytz
import redis
from fastapi import APIRouter, HTTPException, Query, BackgroundTasks
from pydantic import BaseModel, Field

from shared.indicators import compute_all_indicators, add_auto_trend_state_to_candles
from shared.logging import get_logger
from shared.config import get_settings
from HYPERRSI.src.trading.models import get_auto_trend_timeframe

logger = get_logger(__name__)
settings = get_settings()

router = APIRouter()

# Redis ì—°ê²°
redis_client = redis.Redis(
    host=settings.REDIS_HOST,
    port=settings.REDIS_PORT,
    db=0,
    password=settings.REDIS_PASSWORD if settings.REDIS_PASSWORD else None,
    decode_responses=True
)

# íƒ€ì„í”„ë ˆì„ ë§µ
TF_MAP = {1: "1m", 3: "3m", 5: "5m", 15: "15m", 30: "30m", 60: "1h", 240: "4h"}
REVERSE_TF_MAP = {"1m": 1, "3m": 3, "5m": 5, "15m": 15, "30m": 30, "1h": 60, "4h": 240}

# ê¸°ë³¸ ì‹¬ë³¼ ë° íƒ€ì„í”„ë ˆì„
DEFAULT_SYMBOLS = ["BTC-USDT-SWAP", "ETH-USDT-SWAP", "SOL-USDT-SWAP"]
DEFAULT_TIMEFRAMES = ["1m", "3m", "5m", "15m", "30m", "1h", "4h"]
MAX_CANDLES = 1000


class RecalculateRequest(BaseModel):
    """ìº”ë“¤ ì¬ê³„ì‚° ìš”ì²­ ëª¨ë¸"""
    symbols: Optional[List[str]] = Field(
        default=None,
        description="ì¬ê³„ì‚°í•  ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: BTC, ETH, SOL)"
    )
    timeframes: Optional[List[str]] = Field(
        default=None,
        description="ì¬ê³„ì‚°í•  íƒ€ì„í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ëª¨ë“  íƒ€ì„í”„ë ˆì„)"
    )
    max_candles: Optional[int] = Field(
        default=1000,
        description="ì¬ê³„ì‚°í•  ìµœëŒ€ ìº”ë“¤ ìˆ˜",
        ge=100,
        le=5000
    )
    source: Optional[str] = Field(
        default="candlesdb",
        description="ë°ì´í„° ì†ŒìŠ¤: 'candlesdb' (PostgreSQL), 'redis', 'both'"
    )


class RecalculateResponse(BaseModel):
    """ìº”ë“¤ ì¬ê³„ì‚° ì‘ë‹µ ëª¨ë¸"""
    success: bool
    message: str
    results: List[dict]
    total_processed: int
    total_success: int


# ============================================================
# CandlesDB Helper Functions
# ============================================================

def get_candlesdb_connection():
    """CandlesDB ì—°ê²° ìƒì„±"""
    try:
        return psycopg2.connect(
            host=settings.CANDLES_HOST,
            port=settings.CANDLES_PORT,
            database=settings.CANDLES_DATABASE,
            user=settings.CANDLES_USER,
            password=settings.CANDLES_PASSWORD
        )
    except Exception as e:
        logger.error(f"CandlesDB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None


def normalize_symbol_for_db(okx_symbol: str) -> str:
    """OKX ì‹¬ë³¼ì„ DB í…Œì´ë¸”ëª…ìœ¼ë¡œ ë³€í™˜ (BTC-USDT-SWAP -> btc_usdt)"""
    parts = okx_symbol.replace("-SWAP", "").split("-")
    return "_".join(parts).lower()


def get_candles_from_candlesdb(symbol: str, tf_str: str, limit: int = 1000) -> list:
    """CandlesDBì—ì„œ ìº”ë“¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (OHLCVë§Œ)"""
    conn = get_candlesdb_connection()
    if not conn:
        return []

    try:
        table_name = normalize_symbol_for_db(symbol)
        cur = conn.cursor()

        # OHLCV ë°ì´í„°ë§Œ ê°€ì ¸ì˜¤ê¸° (ì§€í‘œëŠ” ì¬ê³„ì‚°í•  ê²ƒì´ë¯€ë¡œ)
        query = f"""
            SELECT time, open, high, low, close, volume
            FROM {table_name}
            WHERE timeframe = %s
            ORDER BY time DESC
            LIMIT %s;
        """
        cur.execute(query, (tf_str, limit + 200))  # warm-upì„ ìœ„í•´ 200ê°œ ì¶”ê°€
        rows = cur.fetchall()

        if not rows:
            logger.warning(f"CandlesDBì—ì„œ ë°ì´í„° ì—†ìŒ: {table_name} {tf_str}")
            return []

        candles = []
        for row in rows:
            ts = int(row[0].timestamp()) if hasattr(row[0], 'timestamp') else int(row[0])
            candles.append({
                "timestamp": ts,
                "open": float(row[1]),
                "high": float(row[2]),
                "low": float(row[3]),
                "close": float(row[4]),
                "volume": float(row[5])
            })

        # ì‹œê°„ìˆœ ì •ë ¬ (ì˜¤ë˜ëœ -> ìµœì‹ )
        candles.sort(key=lambda x: x["timestamp"])
        logger.info(f"CandlesDBì—ì„œ {len(candles)}ê°œ ìº”ë“¤ ë¡œë“œ: {table_name} {tf_str}")
        return candles

    except Exception as e:
        logger.error(f"CandlesDB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    finally:
        conn.close()


def save_candles_to_candlesdb(symbol: str, tf_str: str, candles: list) -> bool:
    """ì¬ê³„ì‚°ëœ ìº”ë“¤ì„ CandlesDBì— ì €ì¥"""
    conn = get_candlesdb_connection()
    if not conn:
        return False

    try:
        table_name = normalize_symbol_for_db(symbol)
        cur = conn.cursor()

        # Upsert query
        upsert_query = f"""
            INSERT INTO {table_name} (
                time, timeframe, open, high, low, close, volume,
                rsi14, atr, ema7, ma20, trend_state, auto_trend_state
            )
            VALUES %s
            ON CONFLICT (time, timeframe)
            DO UPDATE SET
                rsi14 = EXCLUDED.rsi14,
                atr = EXCLUDED.atr,
                ema7 = EXCLUDED.ema7,
                ma20 = EXCLUDED.ma20,
                trend_state = EXCLUDED.trend_state,
                auto_trend_state = EXCLUDED.auto_trend_state;
        """

        # Prepare rows
        rows = []
        for candle in candles:
            ts = candle["timestamp"]
            time_val = datetime.fromtimestamp(ts, tz=timezone.utc)

            row = (
                time_val,
                tf_str,
                Decimal(str(candle["open"])),
                Decimal(str(candle["high"])),
                Decimal(str(candle["low"])),
                Decimal(str(candle["close"])),
                Decimal(str(candle["volume"])),
                Decimal(str(candle.get("rsi", 0))) if candle.get("rsi") else None,
                Decimal(str(candle.get("atr14", 0))) if candle.get("atr14") else None,
                Decimal(str(candle.get("ema7", 0))) if candle.get("ema7") else None,
                Decimal(str(candle.get("sma20", 0))) if candle.get("sma20") else None,
                int(candle.get("trend_state", 0)) if candle.get("trend_state") is not None else None,
                int(candle.get("auto_trend_state", 0)) if candle.get("auto_trend_state") is not None else None,
            )
            rows.append(row)

        # Execute batch upsert
        execute_values(cur, upsert_query, rows)
        conn.commit()

        logger.info(f"CandlesDB ì €ì¥ ì™„ë£Œ: {table_name} {tf_str} - {len(rows)}ê°œ")
        return True

    except Exception as e:
        logger.error(f"CandlesDB ì €ì¥ ì‹¤íŒ¨: {e}")
        if conn:
            conn.rollback()
        return False
    finally:
        conn.close()


# ============================================================
# Redis Helper Functions
# ============================================================

def get_candles_from_redis(symbol: str, tf_str: str) -> list:
    """Redisì—ì„œ ìº”ë“¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    key = f"candles_with_indicators:{symbol}:{tf_str}"
    raw_data = redis_client.lrange(key, 0, -1)

    candles = []
    for item in raw_data:
        try:
            candle = json.loads(item)
            candles.append(candle)
        except json.JSONDecodeError:
            continue

    candles.sort(key=lambda x: x.get("timestamp", 0))
    return candles


def get_auto_trend_candles(symbol: str, auto_trend_tf_str: str) -> list:
    """auto_trend ê³„ì‚°ìš© ìº”ë“¤ ê°€ì ¸ì˜¤ê¸° (Redis)"""
    key = f"candles_with_indicators:{symbol}:{auto_trend_tf_str}"
    raw_data = redis_client.lrange(key, 0, -1)

    candles = []
    for item in raw_data:
        try:
            candle = json.loads(item)
            candles.append(candle)
        except json.JSONDecodeError:
            continue

    candles.sort(key=lambda x: x.get("timestamp", 0))
    return candles


def save_candles_to_redis(symbol: str, tf_str: str, candles: list):
    """ì¬ê³„ì‚°ëœ ìº”ë“¤ Redisì— ì €ì¥"""
    key = f"candles_with_indicators:{symbol}:{tf_str}"

    candles.sort(key=lambda x: x.get("timestamp", 0))

    if len(candles) > 3000:
        candles = candles[-3000:]

    pipe = redis_client.pipeline()
    pipe.delete(key)
    for candle in candles:
        pipe.rpush(key, json.dumps(candle))
    pipe.execute()


# ============================================================
# Recalculation Logic
# ============================================================

def recalculate_single(
    symbol: str,
    tf_str: str,
    max_candles: int = 1000,
    source: str = "candlesdb"
) -> dict:
    """ë‹¨ì¼ ì‹¬ë³¼/íƒ€ì„í”„ë ˆì„ ì¬ê³„ì‚°"""
    result = {
        "symbol": symbol,
        "timeframe": tf_str,
        "success": False,
        "candle_count": 0,
        "source": source,
        "saved_to": [],
        "message": ""
    }

    try:
        # 1. ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ìº”ë“¤ ê°€ì ¸ì˜¤ê¸°
        if source == "candlesdb":
            base_candles = get_candles_from_candlesdb(symbol, tf_str, max_candles)
        elif source == "redis":
            raw_candles = get_candles_from_redis(symbol, tf_str)
            # OHLCVë§Œ ì¶”ì¶œ
            base_candles = []
            for c in raw_candles[-max_candles-200:]:
                base_candles.append({
                    "timestamp": c["timestamp"],
                    "open": c["open"],
                    "high": c["high"],
                    "low": c["low"],
                    "close": c["close"],
                    "volume": c["volume"]
                })
        else:
            result["message"] = f"ì˜ëª»ëœ ì†ŒìŠ¤: {source}"
            return result

        if not base_candles:
            result["message"] = "ë°ì´í„° ì—†ìŒ"
            return result

        logger.info(f"ğŸ“Š ì¬ê³„ì‚° ì‹œì‘: {symbol} {tf_str} - {len(base_candles)}ê°œ ìº”ë“¤ (ì†ŒìŠ¤: {source})")

        # 2. ì§€í‘œ ì¬ê³„ì‚°
        candles_with_ind = compute_all_indicators(base_candles, rsi_period=14, atr_period=14)

        # 3. auto_trend_state ì¬ê³„ì‚°
        auto_trend_tf_str = get_auto_trend_timeframe(tf_str)
        auto_trend_candles = get_auto_trend_candles(symbol, auto_trend_tf_str)

        if auto_trend_candles and len(auto_trend_candles) >= 30:
            timeframe_minutes = REVERSE_TF_MAP.get(tf_str, 5)
            candles_with_ind = add_auto_trend_state_to_candles(
                candles_with_ind,
                auto_trend_candles,
                current_timeframe_minutes=timeframe_minutes
            )
            logger.info(f"  âœ… auto_trend_state ê³„ì‚° ì™„ë£Œ (auto_trend_tf: {auto_trend_tf_str})")
        else:
            for cndl in candles_with_ind:
                cndl["auto_trend_state"] = 0
            logger.warning(f"  âš ï¸ auto_trend ìº”ë“¤ ë¶€ì¡±, 0ìœ¼ë¡œ ì„¤ì •")

        # 4. í•œêµ­ ì‹œê°„ ì¶”ê°€
        seoul_tz = pytz.timezone("Asia/Seoul")
        for cndl in candles_with_ind:
            utc_dt = datetime.fromtimestamp(cndl["timestamp"], tz=timezone.utc)
            dt_seoul = utc_dt.astimezone(seoul_tz)
            cndl["human_time"] = utc_dt.strftime("%Y-%m-%d %H:%M:%S")
            cndl["human_time_kr"] = dt_seoul.strftime("%Y-%m-%d %H:%M:%S")

        # 5. CandlesDBì— ì €ì¥
        if save_candles_to_candlesdb(symbol, tf_str, candles_with_ind):
            result["saved_to"].append("candlesdb")

        # 6. Redisì— ì €ì¥
        save_candles_to_redis(symbol, tf_str, candles_with_ind)
        result["saved_to"].append("redis")

        result["success"] = True
        result["candle_count"] = len(candles_with_ind)
        result["message"] = f"ì¬ê³„ì‚° ì™„ë£Œ â†’ {', '.join(result['saved_to'])}"

        logger.info(f"  âœ… ì €ì¥ ì™„ë£Œ: {symbol} {tf_str} - {len(candles_with_ind)}ê°œ â†’ {result['saved_to']}")

    except Exception as e:
        logger.error(f"ì¬ê³„ì‚° ì‹¤íŒ¨: {symbol} {tf_str} - {e}", exc_info=True)
        result["message"] = str(e)

    return result


# ============================================================
# API Endpoints
# ============================================================

@router.post(
    "/recalculate",
    response_model=RecalculateResponse,
    summary="ìº”ë“¤ ì§€í‘œ ì¬ê³„ì‚°",
    description="""
CandlesDB(PostgreSQL)ì™€ Redisì— ì €ì¥ëœ ìº”ë“¤ ë°ì´í„°ì˜ ì§€í‘œë¥¼ ì¬ê³„ì‚°í•©ë‹ˆë‹¤.

## ì¬ê³„ì‚° ëŒ€ìƒ
- RSI, ATR, EMA, SMA ë“± ê¸°ìˆ ì  ì§€í‘œ
- trend_state (CYCLE ê¸°ë°˜ ì¶”ì„¸ ìƒíƒœ)
- auto_trend_state (ìë™ íŠ¸ë Œë“œ íƒ€ì„í”„ë ˆì„)

## ë°ì´í„° ì†ŒìŠ¤
- **candlesdb** (ê¸°ë³¸ê°’): PostgreSQLì—ì„œ OHLCVë¥¼ ì½ì–´ì„œ ì§€í‘œ ì¬ê³„ì‚°
- **redis**: Redisì—ì„œ ì½ì–´ì„œ ì¬ê³„ì‚°
- **both**: ë‘ ì†ŒìŠ¤ ëª¨ë‘ì—ì„œ ì¬ê³„ì‚°

## ì €ì¥ ìœ„ì¹˜
- ì¬ê³„ì‚°ëœ ë°ì´í„°ëŠ” **CandlesDBì™€ Redis ëª¨ë‘ì— ì €ì¥**ë©ë‹ˆë‹¤.

## ê¸°ë³¸ ë™ì‘
- ì‹¬ë³¼ ë¯¸ì§€ì • ì‹œ: BTC, ETH, SOL
- íƒ€ì„í”„ë ˆì„ ë¯¸ì§€ì • ì‹œ: 1m, 3m, 5m, 15m, 30m, 1h, 4h
- ìµœëŒ€ ìº”ë“¤ ìˆ˜: 1000ê°œ (ê¸°ë³¸ê°’)

## ì£¼ì˜ì‚¬í•­
- ìƒìœ„ íƒ€ì„í”„ë ˆì„ë¶€í„° ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬ë¨ (auto_trend ì˜ì¡´ì„±)
- ëŒ€ëŸ‰ ì¬ê³„ì‚° ì‹œ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŒ
"""
)
async def recalculate_candles(request: RecalculateRequest):
    """ìº”ë“¤ ë°ì´í„° ì§€í‘œ ì¬ê³„ì‚°"""

    symbols = request.symbols or DEFAULT_SYMBOLS
    timeframes = request.timeframes or DEFAULT_TIMEFRAMES
    max_candles = request.max_candles or MAX_CANDLES
    source = request.source or "candlesdb"

    # ìœ íš¨ì„± ê²€ì‚¬
    invalid_tfs = [tf for tf in timeframes if tf not in REVERSE_TF_MAP]
    if invalid_tfs:
        raise HTTPException(
            status_code=400,
            detail=f"ì˜ëª»ëœ íƒ€ì„í”„ë ˆì„: {invalid_tfs}. ì§€ì›: {list(REVERSE_TF_MAP.keys())}"
        )

    if source not in ["candlesdb", "redis", "both"]:
        raise HTTPException(
            status_code=400,
            detail=f"ì˜ëª»ëœ ì†ŒìŠ¤: {source}. ì§€ì›: candlesdb, redis, both"
        )

    logger.info(f"ğŸ”„ ìº”ë“¤ ì¬ê³„ì‚° ì‹œì‘: {symbols} x {timeframes} (ì†ŒìŠ¤: {source})")

    # ìƒìœ„ íƒ€ì„í”„ë ˆì„ë¶€í„° ì²˜ë¦¬ (auto_trend ì˜ì¡´ì„±)
    ordered_timeframes = sorted(
        timeframes,
        key=lambda x: REVERSE_TF_MAP.get(x, 0),
        reverse=True
    )

    results = []

    for symbol in symbols:
        for tf_str in ordered_timeframes:
            result = recalculate_single(symbol, tf_str, max_candles, source)
            results.append(result)

    success_count = sum(1 for r in results if r["success"])

    return RecalculateResponse(
        success=success_count > 0,
        message=f"{len(symbols)}ê°œ ì‹¬ë³¼, {len(timeframes)}ê°œ íƒ€ì„í”„ë ˆì„ ì¬ê³„ì‚° ì™„ë£Œ (ì†ŒìŠ¤: {source})",
        results=results,
        total_processed=len(results),
        total_success=success_count
    )


@router.post(
    "/recalculate/quick",
    summary="ë¹ ë¥¸ ì¬ê³„ì‚° (BTC, ETH, SOL)",
    description="CandlesDBì—ì„œ BTC, ETH, SOLì˜ ëª¨ë“  íƒ€ì„í”„ë ˆì„ì„ ì¬ê³„ì‚°í•˜ê³  CandlesDB + Redisì— ì €ì¥í•©ë‹ˆë‹¤."
)
async def quick_recalculate(
    max_candles: int = Query(default=1000, ge=100, le=3000, description="ìµœëŒ€ ìº”ë“¤ ìˆ˜"),
    source: str = Query(default="candlesdb", description="ë°ì´í„° ì†ŒìŠ¤: candlesdb, redis")
):
    """ë¹ ë¥¸ ì¬ê³„ì‚° (ê¸°ë³¸ ì‹¬ë³¼)"""
    request = RecalculateRequest(
        symbols=DEFAULT_SYMBOLS,
        timeframes=DEFAULT_TIMEFRAMES,
        max_candles=max_candles,
        source=source
    )
    return await recalculate_candles(request)


@router.get(
    "/symbols",
    summary="ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¬ë³¼ ëª©ë¡",
    description="Redisì— ì €ì¥ëœ ìº”ë“¤ ë°ì´í„°ê°€ ìˆëŠ” ì‹¬ë³¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
)
async def get_available_symbols():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¬ë³¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        keys = redis_client.keys("candles_with_indicators:*")

        symbols = set()
        for key in keys:
            parts = key.split(":")
            if len(parts) >= 2:
                symbols.add(parts[1])

        return {
            "symbols": sorted(list(symbols)),
            "count": len(symbols)
        }
    except Exception as e:
        logger.error(f"ì‹¬ë³¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get(
    "/info/{symbol}",
    summary="ì‹¬ë³¼ë³„ ìº”ë“¤ ì •ë³´",
    description="íŠ¹ì • ì‹¬ë³¼ì˜ íƒ€ì„í”„ë ˆì„ë³„ ìº”ë“¤ ë°ì´í„° ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
)
async def get_symbol_info(symbol: str):
    """ì‹¬ë³¼ë³„ ìº”ë“¤ ì •ë³´ ì¡°íšŒ"""
    try:
        info = {"redis": {}, "candlesdb": {}}

        # Redis ì •ë³´
        for tf_str in DEFAULT_TIMEFRAMES:
            key = f"candles_with_indicators:{symbol}:{tf_str}"
            count = redis_client.llen(key)

            if count > 0:
                latest_raw = redis_client.lindex(key, -1)
                oldest_raw = redis_client.lindex(key, 0)

                latest = json.loads(latest_raw) if latest_raw else None
                oldest = json.loads(oldest_raw) if oldest_raw else None

                info["redis"][tf_str] = {
                    "count": count,
                    "oldest_time": oldest.get("human_time_kr") if oldest else None,
                    "latest_time": latest.get("human_time_kr") if latest else None,
                    "latest_close": latest.get("close") if latest else None,
                    "latest_trend_state": latest.get("trend_state") if latest else None,
                    "latest_auto_trend_state": latest.get("auto_trend_state") if latest else None
                }

        # CandlesDB ì •ë³´
        conn = get_candlesdb_connection()
        if conn:
            try:
                table_name = normalize_symbol_for_db(symbol)
                cur = conn.cursor()

                for tf_str in DEFAULT_TIMEFRAMES:
                    query = f"""
                        SELECT
                            COUNT(*) as count,
                            MIN(time) as oldest,
                            MAX(time) as latest
                        FROM {table_name}
                        WHERE timeframe = %s;
                    """
                    cur.execute(query, (tf_str,))
                    row = cur.fetchone()

                    if row and row[0] > 0:
                        info["candlesdb"][tf_str] = {
                            "count": row[0],
                            "oldest_time": row[1].strftime("%Y-%m-%d %H:%M:%S") if row[1] else None,
                            "latest_time": row[2].strftime("%Y-%m-%d %H:%M:%S") if row[2] else None
                        }

                cur.close()
            except Exception as e:
                logger.warning(f"CandlesDB ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            finally:
                conn.close()

        if not info["redis"] and not info["candlesdb"]:
            raise HTTPException(
                status_code=404,
                detail=f"ì‹¬ë³¼ {symbol}ì˜ ìº”ë“¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            )

        return {
            "symbol": symbol,
            "data": info
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì‹¬ë³¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get(
    "/candlesdb/tables",
    summary="CandlesDB í…Œì´ë¸” ëª©ë¡",
    description="CandlesDBì— ì¡´ì¬í•˜ëŠ” ìº”ë“¤ í…Œì´ë¸” ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
)
async def get_candlesdb_tables():
    """CandlesDB í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
    conn = get_candlesdb_connection()
    if not conn:
        raise HTTPException(status_code=503, detail="CandlesDB ì—°ê²° ì‹¤íŒ¨")

    try:
        cur = conn.cursor()
        cur.execute("""
            SELECT table_name
            FROM information_schema.tables
            WHERE table_schema = 'public'
            AND table_type = 'BASE TABLE'
            ORDER BY table_name;
        """)
        tables = [row[0] for row in cur.fetchall()]

        return {
            "tables": tables,
            "count": len(tables)
        }
    except Exception as e:
        logger.error(f"í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        conn.close()
