#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
CandlesDBì˜ auto_trend_stateë¥¼ ì¬ê³„ì‚°í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ìˆ˜ì •ëœ add_auto_trend_state_to_candles ë¡œì§ì„ ì ìš©í•˜ì—¬
ëª¨ë“  íƒ€ì„í”„ë ˆì„ì˜ auto_trend_state ê°’ì„ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python recalculate_candlesdb_auto_trend_state.py --symbol BTC-USDT-SWAP --timeframe 1m --days 30
    python recalculate_candlesdb_auto_trend_state.py --symbol all --timeframe all --days 365

í™˜ê²½ ë³€ìˆ˜ í•„ìš”:
    - CANDLES_HOST, CANDLES_PORT, CANDLES_DATABASE, CANDLES_USER, CANDLES_PASSWORD
"""

import asyncio
import argparse
from datetime import datetime, timedelta, timezone
from decimal import Decimal

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker

from shared.config import get_settings
from shared.logging import get_logger
from shared.indicators._all_indicators import add_auto_trend_state_to_candles

logger = get_logger(__name__)

# ì§€ì› ì‹¬ë³¼ ë§¤í•‘ (OKX ì‹¬ë³¼ â†’ CandlesDB í…Œì´ë¸”ëª…)
SYMBOL_MAPPING = {
    "BTC-USDT-SWAP": "btc_usdt",
    "ETH-USDT-SWAP": "eth_usdt",
    "SOL-USDT-SWAP": "sol_usdt",
    "XRP-USDT-SWAP": "xrp_usdt",
    "DOGE-USDT-SWAP": "doge_usdt",
    "ADA-USDT-SWAP": "ada_usdt",
    "AVAX-USDT-SWAP": "avax_usdt",
    "LINK-USDT-SWAP": "link_usdt",
    "DOT-USDT-SWAP": "dot_usdt",
    "MATIC-USDT-SWAP": "matic_usdt",
}

# íƒ€ì„í”„ë ˆì„ ë§¤í•‘ (ë¬¸ìì—´ â†’ ë¶„)
TIMEFRAME_MAPPING = {
    "1m": 1,
    "3m": 3,
    "5m": 5,
    "15m": 15,
    "30m": 30,
    "1h": 60,
    "4h": 240,
    "1d": 1440,
}


def get_res_timeframe(current_minutes: int) -> str:
    """
    Pine Script Line 32: res_ íƒ€ì„í”„ë ˆì„ ê²°ì • (CYCLEìš© MTF)

    res_ = â‰¤3ë¶„ â†’ 15ë¶„, â‰¤30ë¶„ â†’ 30ë¶„, <240ë¶„ â†’ 60ë¶„, else â†’ 480ë¶„
    """
    if current_minutes <= 3:
        return "15m"
    elif current_minutes <= 30:
        return "30m"
    elif current_minutes < 240:
        return "1h"
    else:
        return "8h"  # 480ë¶„ = 8ì‹œê°„


class CandlesDBRecalculator:
    """CandlesDB auto_trend_state ì¬ê³„ì‚° í´ë˜ìŠ¤"""

    def __init__(self):
        self.settings = get_settings()
        self._engine = None
        self._session_factory = None

    async def _init_connection(self):
        """DB ì—°ê²° ì´ˆê¸°í™”"""
        if self._engine is None:
            db_url = (
                f"postgresql+asyncpg://{self.settings.CANDLES_USER}:{self.settings.CANDLES_PASSWORD}"
                f"@{self.settings.CANDLES_HOST}:{self.settings.CANDLES_PORT}/{self.settings.CANDLES_DATABASE}"
            )
            self._engine = create_async_engine(
                db_url,
                pool_size=1,
                max_overflow=2,
                pool_pre_ping=True,
                pool_recycle=300,
                echo=False
            )
            self._session_factory = async_sessionmaker(
                self._engine,
                class_=AsyncSession,
                expire_on_commit=False
            )
            logger.info(f"âœ… CandlesDB ì—°ê²°: {self.settings.CANDLES_HOST}:{self.settings.CANDLES_PORT}")

    async def close(self):
        """DB ì—°ê²° ì¢…ë£Œ"""
        if self._engine:
            await self._engine.dispose()
            logger.info("DB ì—°ê²° ì¢…ë£Œ")

    async def _get_candles(
        self,
        table_name: str,
        timeframe: str,
        start_date: datetime,
        end_date: datetime
    ) -> list[dict]:
        """
        CandlesDBì—ì„œ ìº”ë“¤ ë°ì´í„° ì¡°íšŒ

        Args:
            table_name: í…Œì´ë¸”ëª… (btc_usdt, eth_usdt ë“±)
            timeframe: íƒ€ì„í”„ë ˆì„ (1m, 15m ë“±)
            start_date: ì‹œì‘ ì¼ì‹œ
            end_date: ì¢…ë£Œ ì¼ì‹œ

        Returns:
            ìº”ë“¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (dict í˜•íƒœ)
        """
        await self._init_connection()

        async with self._session_factory() as session:
            query = text(f"""
                SELECT
                    time, open, high, low, close, volume,
                    rsi14, atr, ema7, ma20, trend_state, auto_trend_state
                FROM {table_name}
                WHERE timeframe = :timeframe
                    AND time >= :start_date
                    AND time <= :end_date
                ORDER BY time ASC
            """)

            result = await session.execute(query, {
                "timeframe": timeframe,
                "start_date": start_date,
                "end_date": end_date
            })
            rows = result.fetchall()

            candles = []
            for row in rows:
                candles.append({
                    "timestamp": int(row.time.timestamp()),
                    "open": float(row.open) if row.open else 0,
                    "high": float(row.high) if row.high else 0,
                    "low": float(row.low) if row.low else 0,
                    "close": float(row.close) if row.close else 0,
                    "volume": float(row.volume) if row.volume else 0,
                    "time": row.time,  # datetime ê°ì²´ ë³´ì¡´ (ì—…ë°ì´íŠ¸ìš©)
                })

            return candles

    async def _update_auto_trend_state(
        self,
        table_name: str,
        timeframe: str,
        candles: list[dict],
        batch_size: int = 500
    ) -> int:
        """
        auto_trend_state ë° ê´€ë ¨ ì§€í‘œ ê°’ë“¤ì„ DBì— ì—…ë°ì´íŠ¸

        Args:
            table_name: í…Œì´ë¸”ëª…
            timeframe: íƒ€ì„í”„ë ˆì„
            candles: auto_trend_stateê°€ ê³„ì‚°ëœ ìº”ë“¤ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸°

        Returns:
            ì—…ë°ì´íŠ¸ëœ í–‰ ìˆ˜
        """
        await self._init_connection()

        # auto_trend_stateë§Œ ì—…ë°ì´íŠ¸ (cycle_bull, cycle_bear, bb_state ì»¬ëŸ¼ì€ DBì— ì—†ìŒ)
        update_query = text(f"""
            UPDATE {table_name}
            SET auto_trend_state = :auto_trend_state
            WHERE time = :time AND timeframe = :timeframe
        """)

        updated = 0
        async with self._session_factory() as session:
            total = len(candles)

            for i in range(0, total, batch_size):
                batch = candles[i:i + batch_size]

                for candle in batch:
                    await session.execute(update_query, {
                        "time": candle["time"],
                        "timeframe": timeframe,
                        "auto_trend_state": int(candle.get("auto_trend_state", 0)),
                    })
                    updated += 1

                await session.commit()

                progress = min(i + batch_size, total)
                logger.info(f"   ì§„í–‰: {progress}/{total} ({progress * 100 // total}%)")

        return updated

    async def recalculate(
        self,
        symbol: str,
        timeframe: str,
        days: int = 30,
        dry_run: bool = False
    ) -> dict:
        """
        íŠ¹ì • ì‹¬ë³¼/íƒ€ì„í”„ë ˆì„ì˜ auto_trend_state ì¬ê³„ì‚°

        Args:
            symbol: OKX ì‹¬ë³¼ (ì˜ˆ: BTC-USDT-SWAP)
            timeframe: íƒ€ì„í”„ë ˆì„ (ì˜ˆ: 1m)
            days: ì¬ê³„ì‚°í•  ê³¼ê±° ë°ì´í„° ì¼ìˆ˜
            dry_run: Trueë©´ ì‹¤ì œ ì—…ë°ì´íŠ¸ ì—†ì´ ê³„ì‚°ë§Œ

        Returns:
            ê²°ê³¼ dict
        """
        await self._init_connection()

        table_name = SYMBOL_MAPPING.get(symbol)
        if not table_name:
            return {"success": False, "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹¬ë³¼: {symbol}"}

        timeframe_minutes = TIMEFRAME_MAPPING.get(timeframe)
        if not timeframe_minutes:
            return {"success": False, "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„í”„ë ˆì„: {timeframe}"}

        logger.info("=" * 80)
        logger.info(f"ğŸ”„ auto_trend_state ì¬ê³„ì‚°: {symbol} ({table_name}) {timeframe}")
        logger.info(f"   ê¸°ê°„: ìµœê·¼ {days}ì¼, dry_run={dry_run}")
        logger.info("=" * 80)

        try:
            # 1. ê¸°ê°„ ì„¤ì •
            end_date = datetime.now(timezone.utc)
            start_date = end_date - timedelta(days=days)

            # BB_State ê³„ì‚°ì„ ìœ„í•œ warm-up ê¸°ê°„ (pivot ë°°ì—´ ì¶•ì  í•„ìš”)
            # - 100-bar MA í•„ìš”
            # - pivot array (50ê°œ) ì¶•ì ì— ìµœì†Œ 200-300ë°” í•„ìš”
            warmup_days = 60  # 60ì¼ ì¶”ê°€ warm-up (15ë¶„ë´‰ ê¸°ì¤€ ì•½ 5760ê°œ ìº”ë“¤)
            warmup_start = start_date - timedelta(days=warmup_days)

            # 2. í˜„ì¬ íƒ€ì„í”„ë ˆì„ ìº”ë“¤ ë¡œë“œ (warm-up í¬í•¨)
            logger.info(f"\n1ï¸âƒ£ {timeframe} ìº”ë“¤ ë¡œë“œ ì¤‘ (warm-up {warmup_days}ì¼ í¬í•¨)...")
            all_candles = await self._get_candles(table_name, timeframe, warmup_start, end_date)

            if not all_candles:
                return {"success": False, "error": f"ë°ì´í„° ì—†ìŒ: {table_name} {timeframe}"}

            logger.info(f"   âœ… {len(all_candles):,}ê°œ ìº”ë“¤ ë¡œë“œ ì™„ë£Œ (warm-up í¬í•¨)")

            # 3. CYCLEìš© MTF ìº”ë“¤ ë¡œë“œ (res_ íƒ€ì„í”„ë ˆì„)
            res_timeframe = get_res_timeframe(timeframe_minutes)
            logger.info(f"\n2ï¸âƒ£ CYCLE MTF ({res_timeframe}) ìº”ë“¤ ë¡œë“œ ì¤‘...")

            # MTF ë°ì´í„°ë„ warm-up ê¸°ê°„ì„ í¬í•¨í•´ì•¼ í•¨
            mtf_start = warmup_start - timedelta(days=30)  # ì¶”ê°€ 30ì¼ ì—¬ìœ 
            auto_trend_candles = await self._get_candles(table_name, res_timeframe, mtf_start, end_date)

            if not auto_trend_candles:
                logger.warning(f"   âš ï¸ MTF ë°ì´í„° ì—†ìŒ, ë¦¬ìƒ˜í”Œë§ ì‚¬ìš© ì˜ˆì •")
                auto_trend_candles = None
            else:
                logger.info(f"   âœ… {len(auto_trend_candles):,}ê°œ MTF ìº”ë“¤ ë¡œë“œ ì™„ë£Œ")

            # 4. auto_trend_state ì¬ê³„ì‚° (warm-up í¬í•¨ ì „ì²´ ìº”ë“¤ì— ëŒ€í•´)
            logger.info(f"\n3ï¸âƒ£ auto_trend_state ì¬ê³„ì‚° ì¤‘ (ì „ì²´ {len(all_candles):,}ê°œ ìº”ë“¤)...")

            result_candles = add_auto_trend_state_to_candles(
                candles=all_candles,  # warm-up í¬í•¨ ì „ì²´ ìº”ë“¤ ì‚¬ìš©
                auto_trend_candles=auto_trend_candles if auto_trend_candles else [],
                current_timeframe_minutes=timeframe_minutes
            )

            logger.info(f"   âœ… {len(result_candles):,}ê°œ ìº”ë“¤ ê³„ì‚° ì™„ë£Œ")

            # 5. ëŒ€ìƒ ê¸°ê°„ ìº”ë“¤ë§Œ í•„í„°ë§ (warm-up ê¸°ê°„ ì œì™¸)
            target_candles = [
                c for c in result_candles
                if c["time"] >= start_date
            ]
            logger.info(f"   âœ… ëŒ€ìƒ ê¸°ê°„ ìº”ë“¤: {len(target_candles):,}ê°œ (warm-up {len(result_candles) - len(target_candles):,}ê°œ ì œì™¸)")

            # 6. í†µê³„ ì¶œë ¥
            auto_states = [c.get("auto_trend_state", 0) for c in target_candles]
            count_2 = auto_states.count(2)
            count_0 = auto_states.count(0)
            count_minus2 = auto_states.count(-2)
            total = len(auto_states)

            logger.info(f"\n7ï¸âƒ£ ì¬ê³„ì‚° í†µê³„ (ëŒ€ìƒ ê¸°ê°„ë§Œ):")
            logger.info(f"   - ê°•í•œ ìƒìŠ¹ (2): {count_2:,}ê°œ ({count_2 * 100 / total:.1f}%)")
            logger.info(f"   - ì¤‘ë¦½ (0): {count_0:,}ê°œ ({count_0 * 100 / total:.1f}%)")
            logger.info(f"   - ê°•í•œ í•˜ë½ (-2): {count_minus2:,}ê°œ ({count_minus2 * 100 / total:.1f}%)")

            # 8. ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ (ëŒ€ìƒ ê¸°ê°„ë§Œ)
            if dry_run:
                logger.info(f"\n8ï¸âƒ£ [DRY RUN] ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€")
                updated = 0
            else:
                logger.info(f"\n8ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘ ({len(target_candles):,}ê°œ ìº”ë“¤)...")
                updated = await self._update_auto_trend_state(
                    table_name, timeframe, target_candles  # warm-up ì œì™¸ ëŒ€ìƒ ê¸°ê°„ë§Œ
                )
                logger.info(f"   âœ… {updated:,}ê°œ í–‰ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

            logger.info("\n" + "=" * 80)
            logger.info(f"âœ… ì¬ê³„ì‚° ì™„ë£Œ: {symbol} {timeframe}")
            logger.info("=" * 80)

            return {
                "success": True,
                "symbol": symbol,
                "timeframe": timeframe,
                "candles_processed": len(target_candles),  # ëŒ€ìƒ ê¸°ê°„ ìº”ë“¤ ìˆ˜
                "warmup_candles": len(result_candles) - len(target_candles),
                "rows_updated": updated,
                "stats": {
                    "strong_bull": count_2,
                    "neutral": count_0,
                    "strong_bear": count_minus2
                }
            }

        except Exception as e:
            logger.error(f"âŒ ì¬ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="CandlesDB auto_trend_state ì¬ê³„ì‚°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ë‹¨ì¼ ì‹¬ë³¼/íƒ€ì„í”„ë ˆì„ ì¬ê³„ì‚°
  python recalculate_candlesdb_auto_trend_state.py --symbol BTC-USDT-SWAP --timeframe 1m --days 30

  # ëª¨ë“  íƒ€ì„í”„ë ˆì„ ì¬ê³„ì‚°
  python recalculate_candlesdb_auto_trend_state.py --symbol BTC-USDT-SWAP --timeframe all --days 365

  # ì—¬ëŸ¬ ì‹¬ë³¼ ì¬ê³„ì‚°
  python recalculate_candlesdb_auto_trend_state.py --symbol all --timeframe 1m --days 30

  # ë“œë¼ì´ëŸ° (ì‹¤ì œ ì—…ë°ì´íŠ¸ ì—†ì´ í™•ì¸)
  python recalculate_candlesdb_auto_trend_state.py --symbol BTC-USDT-SWAP --timeframe 1m --dry-run

ì§€ì› ì‹¬ë³¼: BTC-USDT-SWAP, ETH-USDT-SWAP, SOL-USDT-SWAP, XRP-USDT-SWAP, DOGE-USDT-SWAP,
           ADA-USDT-SWAP, AVAX-USDT-SWAP, LINK-USDT-SWAP, DOT-USDT-SWAP, MATIC-USDT-SWAP

ì§€ì› íƒ€ì„í”„ë ˆì„: 1m, 3m, 5m, 15m, 30m, 1h, 4h, 1d
        """
    )
    parser.add_argument("--symbol", "-s", required=True,
                        help="ì‹¬ë³¼ (ì˜ˆ: BTC-USDT-SWAP) ë˜ëŠ” 'all'")
    parser.add_argument("--timeframe", "-t", required=True,
                        help="íƒ€ì„í”„ë ˆì„ (ì˜ˆ: 1m) ë˜ëŠ” 'all'")
    parser.add_argument("--days", "-d", type=int, default=30,
                        help="ì¬ê³„ì‚°í•  ê³¼ê±° ë°ì´í„° ì¼ìˆ˜ (ê¸°ë³¸: 30)")
    parser.add_argument("--dry-run", action="store_true",
                        help="ì‹¤ì œ ì—…ë°ì´íŠ¸ ì—†ì´ ê³„ì‚°ë§Œ ìˆ˜í–‰")

    args = parser.parse_args()

    recalculator = CandlesDBRecalculator()

    try:
        # ì‹¬ë³¼ ëª©ë¡ ê²°ì •
        if args.symbol.lower() == "all":
            symbols = list(SYMBOL_MAPPING.keys())
        else:
            symbols = [args.symbol]

        # íƒ€ì„í”„ë ˆì„ ëª©ë¡ ê²°ì •
        if args.timeframe.lower() == "all":
            timeframes = list(TIMEFRAME_MAPPING.keys())
        else:
            timeframes = [args.timeframe]

        results = []
        total_updated = 0
        total_processed = 0

        for symbol in symbols:
            for timeframe in timeframes:
                result = await recalculator.recalculate(
                    symbol=symbol,
                    timeframe=timeframe,
                    days=args.days,
                    dry_run=args.dry_run
                )
                results.append(result)

                if result.get("success"):
                    total_updated += result.get("rows_updated", 0)
                    total_processed += result.get("candles_processed", 0)

        # ìµœì¢… ìš”ì•½
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š ì „ì²´ ì¬ê³„ì‚° ìš”ì•½")
        logger.info("=" * 80)
        logger.info(f"   - ì²˜ë¦¬ëœ ìº”ë“¤: {total_processed:,}ê°œ")
        logger.info(f"   - ì—…ë°ì´íŠ¸ëœ í–‰: {total_updated:,}ê°œ")
        logger.info(f"   - ì„±ê³µ: {sum(1 for r in results if r.get('success'))}ê±´")
        logger.info(f"   - ì‹¤íŒ¨: {sum(1 for r in results if not r.get('success'))}ê±´")
        logger.info("=" * 80)

    finally:
        await recalculator.close()


if __name__ == "__main__":
    asyncio.run(main())
