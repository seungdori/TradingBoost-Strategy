# TradingBoost-Strategy ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ë¶„ì„ ë° ì„¤ê³„

**ì‘ì„±ì¼**: 2025-10-08
**ëŒ€ìƒ ì‹œìŠ¤í…œ**: TradingBoost-Strategy (Python 3.9+ ì•”í˜¸í™”í ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ)
**í˜„ì¬ ìƒíƒœ**: ëª¨ë…¸ë ˆí¬ (HYPERRSI + GRID ì „ëµ, shared ëª¨ë“ˆ)

---

## ëª©ì°¨

1. [í˜„ì¬ ì•„í‚¤í…ì²˜ ë¶„ì„](#1-í˜„ì¬-ì•„í‚¤í…ì²˜-ë¶„ì„)
2. [ì œì•ˆëœ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ êµ¬ì¡°](#2-ì œì•ˆëœ-ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤-êµ¬ì¡°)
3. [ì„œë¹„ìŠ¤ ê°„ í†µì‹  íŒ¨í„´](#3-ì„œë¹„ìŠ¤-ê°„-í†µì‹ -íŒ¨í„´)
4. [ë°ì´í„° ê´€ë¦¬ ì „ëµ](#4-ë°ì´í„°-ê´€ë¦¬-ì „ëµ)
5. [ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡œë“œë§µ](#5-ë§ˆì´ê·¸ë ˆì´ì…˜-ë¡œë“œë§µ)
6. [ë¹„ë™ê¸° ì•„í‚¤í…ì²˜ íŒ¨í„´](#6-ë¹„ë™ê¸°-ì•„í‚¤í…ì²˜-íŒ¨í„´)
7. [ìš´ì˜ ê³ ë ¤ì‚¬í•­](#7-ìš´ì˜-ê³ ë ¤ì‚¬í•­)
8. [ìµœì¢… ê¶Œì¥ì‚¬í•­](#8-ìµœì¢…-ê¶Œì¥ì‚¬í•­)

---

## 1. í˜„ì¬ ì•„í‚¤í…ì²˜ ë¶„ì„

### 1.1 ëª¨ë…¸ë ˆí¬ êµ¬ì¡°

```
TradingBoost-Strategy/
â”œâ”€â”€ HYPERRSI/              # RSI + íŠ¸ë Œë“œ ê¸°ë°˜ ì „ëµ (í¬íŠ¸ 8000)
â”‚   â”œâ”€â”€ main.py           # FastAPI ì•±
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/routes/   # ë„ë©”ì¸ë³„ ë¼ìš°í„° (trading, order, position, account...)
â”‚   â”‚   â”œâ”€â”€ core/         # ë°ì´í„°ë² ì´ìŠ¤, ì—ëŸ¬ í•¸ë“¤ëŸ¬, Celery ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ services/     # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (redis_service, trading_service)
â”‚   â”‚   â”œâ”€â”€ tasks/        # Celery ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (trading_tasks, websocket_tasks)
â”‚   â”‚   â”œâ”€â”€ data_collector/ # ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ trading/      # ê±°ë˜ ì‹¤í–‰ ë¡œì§
â”‚   â””â”€â”€ start_celery_worker.sh
â”‚
â”œâ”€â”€ GRID/                  # ê·¸ë¦¬ë“œ íŠ¸ë ˆì´ë”© ì „ëµ (í¬íŠ¸ 8012)
â”‚   â”œâ”€â”€ main.py           # FastAPI ì•±
â”‚   â”œâ”€â”€ strategies/       # ê·¸ë¦¬ë“œ ì•Œê³ ë¦¬ì¦˜
â”‚   â”œâ”€â”€ routes/           # API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ jobs/             # Celery ì‘ì—… + worker_manager (multiprocessing)
â”‚   â”œâ”€â”€ websocket/        # ì‹¤ì‹œê°„ ê°€ê²© í”¼ë“œ
â”‚   â”œâ”€â”€ handlers/         # ê±°ë˜ì†Œë³„ í•¸ë“¤ëŸ¬ (Upbit, OKX...)
â”‚   â””â”€â”€ services/         # bot_state_service, trading_service
â”‚
â””â”€â”€ shared/               # ê³µí†µ ëª¨ë“ˆ
    â”œâ”€â”€ config.py         # í†µí•© ì„¤ì • (pydantic-settings)
    â”œâ”€â”€ exchange_apis/    # CCXT ë˜í¼ (ExchangeStore)
    â”œâ”€â”€ database/         # Redis/PostgreSQL ì—°ê²° ê´€ë¦¬
    â”œâ”€â”€ notifications/    # Telegram ì•Œë¦¼
    â”œâ”€â”€ utils/            # ì¬ì‹œë„ ë¡œì§, ê²€ì¦ í—¬í¼
    â”œâ”€â”€ constants/        # ê³µìœ  ìƒìˆ˜
    â””â”€â”€ indicators/       # ê¸°ìˆ ì  ì§€í‘œ
```

### 1.2 ê¸°ìˆ  ìŠ¤íƒ

- **API í”„ë ˆì„ì›Œí¬**: FastAPI (Python 3.9+)
- **ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
  - HYPERRSI: Celery (Redis broker/backend, DB 1)
  - GRID: multiprocessing (spawn/fork)
- **ë°ì´í„° ì €ì¥ì†Œ**:
  - Redis (DB 0: ì•± ë°ì´í„°, DB 1: Celery)
  - PostgreSQL (ì„ íƒì , í˜„ì¬ ìµœì†Œ ì‚¬ìš©)
- **ì‹¤ì‹œê°„ í†µì‹ **: WebSockets (OKX, Binance ë“±)
- **ê±°ë˜ì†Œ API**: CCXT (OKX, Binance, Bitget, Upbit, Bybit)

### 1.3 ê²°í•©ë„(Coupling) ë¶„ì„

#### ë†’ì€ ê²°í•©ë„ ì˜ì—­

**A. Shared ëª¨ë“ˆ ì˜ì¡´ì„±**

```python
# HYPERRSI/main.py
from shared.config import settings
from shared.logging import get_logger, setup_json_logger
from shared.database.session import init_db, close_db
from shared.database.redis import init_redis, close_redis
from shared.errors import register_exception_handlers
from shared.utils.task_tracker import TaskTracker

# GRID/strategies/grid.py
from shared.utils import parse_bool, parse_timeframe
from shared.validation.trading_validators import check_order_validity
from shared.utils.exchange_precision import round_to_precision
from shared.utils.async_helpers import async_debounce, custom_sleep
```

**ê²°í•©ë„ ì ìˆ˜**: âš ï¸ **ë†’ìŒ** (9/10)
- **ë¬¸ì œì **:
  - ëª¨ë“  ì „ëµì´ shared ëª¨ë“ˆì— ê°•í•˜ê²Œ ì˜ì¡´
  - shared ëª¨ë“ˆ ë³€ê²½ ì‹œ ëª¨ë“  ì „ëµ ì¬ë°°í¬ í•„ìš”
  - ë…ë¦½ì ì¸ ìŠ¤ì¼€ì¼ë§ ë¶ˆê°€ëŠ¥

**B. Redis ìƒíƒœ ê³µìœ **

```python
# HYPERRSI/src/tasks/trading_tasks.py
REDIS_KEY_TRADING_STATUS = "user:{okx_uid}:trading:status"
REDIS_KEY_TASK_RUNNING = "user:{okx_uid}:task_running"
REDIS_KEY_SYMBOL_STATUS = "user:{okx_uid}:symbol:{symbol}:status"

# GRID/database/redis_database.py
# ìœ ì‚¬í•œ í‚¤ íŒ¨í„´ ì‚¬ìš©, ì¤‘ì•™ ì •ì˜ ì—†ìŒ
```

**ê²°í•©ë„ ì ìˆ˜**: âš ï¸ **ì¤‘ìƒ** (7/10)
- **ë¬¸ì œì **:
  - Redis í‚¤ ìŠ¤í‚¤ë§ˆê°€ ì½”ë“œì— ë¶„ì‚°
  - í‚¤ ì¶©ëŒ ê°€ëŠ¥ì„±
  - íŠ¸ëœì­ì…˜ ê²½ê³„ ë¶ˆëª…í™•

**C. WebSocket ì—°ê²° ê´€ë¦¬**

```python
# HYPERRSI/src/tasks/websocket_tasks.py
ws_manager = OKXWebsocketManager()  # ì‹±ê¸€í†¤

# GRID/websocket/okx_ws.py
class OKXWebsocket:
    def __init__(self, api_key, secret_key, passphrase, user_id, exchange_name):
        self.ws_url = "wss://ws.okx.com:8443/ws/v5/private"
```

**ê²°í•©ë„ ì ìˆ˜**: âš ï¸ **ì¤‘** (5/10)
- **ë¬¸ì œì **:
  - WebSocket ì—°ê²°ì´ ì „ëµë³„ë¡œ ì¤‘ë³µ
  - ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ë°° ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ
  - ì—°ê²° ìˆ˜ ìµœì í™” ë¶ˆê°€

**D. ê±°ë˜ì†Œ API í´ë¼ì´ì–¸íŠ¸**

```python
# shared/exchange_apis/exchange_store.py
class ExchangeStore:
    # CCXT ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
```

**ê²°í•©ë„ ì ìˆ˜**: âœ… **ë‚®ìŒ** (3/10)
- **ì¥ì **: ì´ë¯¸ ì–´ëŠ ì •ë„ ì¶”ìƒí™”ë¨
- **ê°œì„  ì—¬ì§€**: ë³„ë„ ì„œë¹„ìŠ¤ë¡œ ë¶„ë¦¬ ê°€ëŠ¥

#### ë‚®ì€ ê²°í•©ë„ ì˜ì—­

**A. ì „ëµ ë¡œì§**

```python
# HYPERRSI/src/trading/execute_trading_logic.py
# GRID/strategies/grid.py
```

**ê²°í•©ë„ ì ìˆ˜**: âœ… **ë§¤ìš° ë‚®ìŒ** (2/10)
- **ì¥ì **: ì „ëµë³„ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì´ ë…ë¦½ì 

**B. Telegram ì•Œë¦¼**

```python
# shared/notifications/telegram.py
```

**ê²°í•©ë„ ì ìˆ˜**: âœ… **ë‚®ìŒ** (3/10)
- **ì¥ì **: ì´ë¯¸ ëª¨ë“ˆí™”ë¨, ì„œë¹„ìŠ¤ë¡œ ì‰½ê²Œ ë¶„ë¦¬ ê°€ëŠ¥

### 1.4 ë°ì´í„° íë¦„ ë¶„ì„

```mermaid
graph TD
    A[ì‚¬ìš©ì ìš”ì²­] -->|HTTP| B[FastAPI HYPERRSI:8000]
    A -->|HTTP| C[FastAPI GRID:8012]

    B --> D[Redis DB 0]
    C --> D

    B --> E[Celery Worker]
    E --> F[Redis DB 1 Broker/Backend]

    C --> G[Multiprocessing Workers]

    E --> H[WebSocket Manager HYPERRSI]
    G --> I[WebSocket Manager GRID]

    H --> J[OKX WebSocket]
    I --> J

    B --> K[CCXT Exchange API]
    C --> K

    B --> L[PostgreSQL Optional]
    C --> L

    E --> M[Telegram Bot]
    G --> M
```

**ë³‘ëª© í˜„ìƒ**:
1. **Redis DB 0**: ëª¨ë“  ì „ëµì˜ ìƒíƒœ ë°ì´í„° ì§‘ì¤‘
2. **WebSocket ì—°ê²°**: ì „ëµë³„ ì¤‘ë³µ ì—°ê²°
3. **CCXT API í˜¸ì¶œ**: Rate limit ê³µìœ  ê´€ë¦¬ ë¶€ì¬

### 1.5 í˜„ì¬ ì•„í‚¤í…ì²˜ì˜ ê°•ì 

âœ… **ê°•ì **:
1. **ëª¨ë…¸ë ˆí¬ ì´ì **: ì½”ë“œ ì¬ì‚¬ìš©, ì¼ê´€ëœ ë„êµ¬ ì²´ì¸
2. **shared ëª¨ë“ˆ**: DRY ì›ì¹™ ì¤€ìˆ˜
3. **FastAPI**: ê³ ì„±ëŠ¥ ë¹„ë™ê¸° API
4. **Redis**: ë¹ ë¥¸ ìƒíƒœ ê´€ë¦¬
5. **Celery/Multiprocessing**: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì²˜ë¦¬

### 1.6 í˜„ì¬ ì•„í‚¤í…ì²˜ì˜ ì•½ì 

âŒ **ì•½ì **:
1. **ìŠ¤ì¼€ì¼ë§ í•œê³„**: ì „ëµë³„ ë…ë¦½ì  ìŠ¤ì¼€ì¼ë§ ë¶ˆê°€
2. **ë°°í¬ ë³µì¡ë„**: í•œ ì „ëµ ë³€ê²½ ì‹œ ì „ì²´ ì¬ë°°í¬
3. **ì¥ì•  ê²©ë¦¬**: í•œ ì „ëµ ì¥ì• ê°€ ì „ì²´ ì˜í–¥ ê°€ëŠ¥
4. **ë¦¬ì†ŒìŠ¤ ê²½ìŸ**: Redis/WebSocket ë¦¬ì†ŒìŠ¤ ê²½ìŸ
5. **í…ŒìŠ¤íŠ¸ ë³µì¡ë„**: í†µí•© í…ŒìŠ¤íŠ¸ ì‹œ ì „ì²´ ì‹œìŠ¤í…œ í•„ìš”
6. **ê¸°ìˆ  ìŠ¤íƒ ê³ ì •**: ëª¨ë“  ì „ëµì´ ë™ì¼í•œ ê¸°ìˆ  ìŠ¤íƒ ì‚¬ìš©

---

## 2. ì œì•ˆëœ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ êµ¬ì¡°

### 2.1 ì„œë¹„ìŠ¤ ë¶„í•´ ì›ì¹™

**ë„ë©”ì¸ ì£¼ë„ ì„¤ê³„(DDD) ì›ì¹™**:
- **Bounded Context**: ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸ ê²½ê³„ë¡œ ë¶„ë¦¬
- **Single Responsibility**: ê° ì„œë¹„ìŠ¤ëŠ” í•˜ë‚˜ì˜ ì±…ì„
- **Data Ownership**: ê° ì„œë¹„ìŠ¤ëŠ” ìì‹ ì˜ ë°ì´í„° ì†Œìœ 
- **Independent Deployment**: ë…ë¦½ì  ë°°í¬ ê°€ëŠ¥

**ì•”í˜¸í™”í íŠ¸ë ˆì´ë”© ë„ë©”ì¸ íŠ¹ìˆ˜ì„±**:
- **ì €ì§€ì—° ìš”êµ¬ì‚¬í•­**: ì£¼ë¬¸ ì‹¤í–‰ ì§€ì—° ìµœì†Œí™”
- **ê³ ê°€ìš©ì„±**: 24/7 ìš´ì˜ í•„ìˆ˜
- **ë°ì´í„° ì¼ê´€ì„±**: ì£¼ë¬¸/í¬ì§€ì…˜ ìƒíƒœ ì •í•©ì„± ë³´ì¥
- **ì‹¤ì‹œê°„ì„±**: ì‹œì¥ ë°ì´í„° ì‹¤ì‹œê°„ ì²˜ë¦¬

### 2.2 ì œì•ˆëœ ì„œë¹„ìŠ¤ ëª©ë¡

#### í•µì‹¬ ì„œë¹„ìŠ¤ (Core Services)

##### 1. **Strategy Execution Service - HYPERRSI** ğŸ¯

**ì±…ì„**:
- HYPERRSI ì „ëµ ì‹¤í–‰ ë¡œì§
- RSI + íŠ¸ë Œë“œ ë¶„ì„
- ì‹ í˜¸ ìƒì„± ë° ê²€ì¦

**API ì—”ë“œí¬ì¸íŠ¸**:
```
POST   /api/strategy/hyperrsi/activate
POST   /api/strategy/hyperrsi/deactivate
GET    /api/strategy/hyperrsi/status/{user_id}
GET    /api/strategy/hyperrsi/signals/{user_id}
POST   /api/strategy/hyperrsi/backtest
```

**ë°ì´í„° ì†Œìœ **:
- Redis: `hyperrsi:{user_id}:*` í‚¤ íŒ¨í„´
- PostgreSQL: `hyperrsi_signals`, `hyperrsi_state` í…Œì´ë¸”

**ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
- Celery ì›Œì»¤ (ì „ìš© í: `hyperrsi_queue`)

**ë°°í¬**:
- Docker ì»¨í…Œì´ë„ˆ
- ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§: ìœ ì € ìˆ˜ì— ë¹„ë¡€

**í¬íŠ¸**: 8001

---

##### 2. **Strategy Execution Service - GRID** ğŸ¯

**ì±…ì„**:
- GRID íŠ¸ë ˆì´ë”© ì „ëµ ì‹¤í–‰
- ê·¸ë¦¬ë“œ ë ˆë²¨ ê³„ì‚°
- ì£¼ë¬¸ ìƒì„± ë° ëª¨ë‹ˆí„°ë§

**API ì—”ë“œí¬ì¸íŠ¸**:
```
POST   /api/strategy/grid/activate
POST   /api/strategy/grid/deactivate
GET    /api/strategy/grid/status/{user_id}
GET    /api/strategy/grid/levels/{user_id}
POST   /api/strategy/grid/adjust
```

**ë°ì´í„° ì†Œìœ **:
- Redis: `grid:{user_id}:*` í‚¤ íŒ¨í„´
- PostgreSQL: `grid_levels`, `grid_state` í…Œì´ë¸”

**ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
- ì „ìš© Celery ì›Œì»¤ ë˜ëŠ” asyncio TaskGroup

**ë°°í¬**:
- Docker ì»¨í…Œì´ë„ˆ
- ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§: ìœ ì € ìˆ˜ì— ë¹„ë¡€

**í¬íŠ¸**: 8002

---

##### 3. **Market Data Service** ğŸ“Š

**ì±…ì„**:
- WebSocket ì—°ê²° ê´€ë¦¬ (í†µí•©)
- ì‹¤ì‹œê°„ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
- ì‹œì¥ ë°ì´í„° ì •ê·œí™” ë° ë¶„ë°°
- ìº”ë“¤ìŠ¤í‹± ë°ì´í„° ìƒì„±

**API ì—”ë“œí¬ì¸íŠ¸**:
```
GET    /api/market/ticker/{exchange}/{symbol}
GET    /api/market/orderbook/{exchange}/{symbol}
GET    /api/market/candles/{exchange}/{symbol}/{timeframe}
WS     /ws/market/subscribe
```

**ë°ì´í„° ì†Œìœ **:
- Redis: `market:{exchange}:{symbol}:*` (ì‹¤ì‹œê°„ ë°ì´í„°)
- Redis Streams: ê°€ê²© ì—…ë°ì´íŠ¸ ì´ë²¤íŠ¸ ë°œí–‰
- PostgreSQL: `market_candles` (íˆìŠ¤í† ë¦¬)

**ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
- WebSocket ì—°ê²° ê´€ë¦¬ì (asyncio)
- ìº”ë“¤ìŠ¤í‹± ì§‘ê³„ ì‘ì—… (Celery Beat)

**ë°°í¬**:
- Stateful ì„œë¹„ìŠ¤ (WebSocket ì—°ê²° ìœ ì§€)
- ê±°ë˜ì†Œë³„ ì¸ìŠ¤í„´ìŠ¤ (ì˜ˆ: okx-marketdata, binance-marketdata)

**í¬íŠ¸**: 8003

---

##### 4. **Order Management Service (OMS)** ğŸ“

**ì±…ì„**:
- ì£¼ë¬¸ ìƒì„±/ì·¨ì†Œ/ìˆ˜ì •
- ì£¼ë¬¸ ìƒíƒœ ì¶”ì 
- ì²´ê²° ë‚´ì—­ ê¸°ë¡
- ì£¼ë¬¸ ê²€ì¦ ë¡œì§

**API ì—”ë“œí¬ì¸íŠ¸**:
```
POST   /api/orders/create
POST   /api/orders/cancel/{order_id}
GET    /api/orders/status/{order_id}
GET    /api/orders/list/{user_id}
GET    /api/orders/fills/{order_id}
POST   /api/orders/batch
```

**ë°ì´í„° ì†Œìœ **:
- Redis: `order:{order_id}:*` (ì‹¤ì‹œê°„ ìƒíƒœ)
- PostgreSQL: `orders`, `order_fills` (ì˜êµ¬ ì €ì¥)

**ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
- ì£¼ë¬¸ ì²´ê²° ëª¨ë‹ˆí„°ë§ (WebSocket ì´ë²¤íŠ¸ ì†Œë¹„)
- ì£¼ë¬¸ ìƒíƒœ ë™ê¸°í™” (Celery ì‘ì—…)

**ë°°í¬**:
- ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ (ì£¼ë¬¸ ë³¼ë¥¨ì— ë¹„ë¡€)
- ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© (user_id ê¸°ì¤€)

**í¬íŠ¸**: 8004

---

##### 5. **Exchange Gateway Service** ğŸŒ

**ì±…ì„**:
- CCXT API ì¶”ìƒí™” ê³„ì¸µ
- ê±°ë˜ì†Œë³„ API í˜¸ì¶œ ê´€ë¦¬
- Rate limiting ë° ì—ëŸ¬ í•¸ë“¤ë§
- API í‚¤ ê´€ë¦¬ (ì•”í˜¸í™”)

**API ì—”ë“œí¬ì¸íŠ¸**:
```
POST   /api/exchange/execute
GET    /api/exchange/balance/{user_id}/{exchange}
GET    /api/exchange/positions/{user_id}/{exchange}
GET    /api/exchange/markets/{exchange}
POST   /api/exchange/withdraw
```

**ë°ì´í„° ì†Œìœ **:
- Redis: `exchange:ratelimit:{exchange}:{endpoint}` (Rate limit ì¹´ìš´í„°)
- PostgreSQL: `exchange_credentials` (ì•”í˜¸í™”ëœ API í‚¤)
- ë©”ëª¨ë¦¬ ìºì‹œ: CCXT ì¸ìŠ¤í„´ìŠ¤ í’€

**ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
- Rate limit ë¦¬ì…‹ (Redis TTL ê¸°ë°˜)
- ì”ê³  ë™ê¸°í™” (ì£¼ê¸°ì  í´ë§)

**ë°°í¬**:
- ê±°ë˜ì†Œë³„ ì „ìš© ì¸ìŠ¤í„´ìŠ¤ (ì˜ˆ: okx-gateway, binance-gateway)
- ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ (API í˜¸ì¶œ ë³¼ë¥¨ì— ë¹„ë¡€)

**í¬íŠ¸**: 8005

---

##### 6. **Position Management Service** ğŸ“ˆ

**ì±…ì„**:
- í¬ì§€ì…˜ ìƒíƒœ ì¶”ì 
- ì†ìµ ê³„ì‚° (PnL)
- í¬ì§€ì…˜ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§
- ì²­ì‚°ê°€ ê³„ì‚°

**API ì—”ë“œí¬ì¸íŠ¸**:
```
GET    /api/positions/{user_id}
GET    /api/positions/{user_id}/{symbol}
GET    /api/positions/pnl/{user_id}
POST   /api/positions/close/{position_id}
GET    /api/positions/risk/{user_id}
```

**ë°ì´í„° ì†Œìœ **:
- Redis: `position:{user_id}:{symbol}:*` (ì‹¤ì‹œê°„)
- PostgreSQL: `positions`, `position_history`

**ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
- ì‹¤ì‹œê°„ PnL ê³„ì‚° (Market Data ì´ë²¤íŠ¸ ì†Œë¹„)
- ë¦¬ìŠ¤í¬ ì•Œë¦¼ (Celery Beat)

**ë°°í¬**:
- Stateful ì„œë¹„ìŠ¤ (í¬ì§€ì…˜ ìƒíƒœ ìœ ì§€)
- ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ (ìœ ì € ìƒ¤ë”©)

**í¬íŠ¸**: 8006

---

#### ì§€ì› ì„œë¹„ìŠ¤ (Supporting Services)

##### 7. **Notification Service** ğŸ“¬

**ì±…ì„**:
- Telegram ë´‡ ê´€ë¦¬
- ì•Œë¦¼ í ê´€ë¦¬
- ì•Œë¦¼ í…œí”Œë¦¿ ë Œë”ë§
- ì•Œë¦¼ íˆìŠ¤í† ë¦¬

**API ì—”ë“œí¬ì¸íŠ¸**:
```
POST   /api/notifications/send
POST   /api/notifications/broadcast
GET    /api/notifications/history/{user_id}
POST   /api/notifications/subscribe
```

**ë°ì´í„° ì†Œìœ **:
- Redis: `notification:queue:*` (ë©”ì‹œì§€ í)
- PostgreSQL: `notification_history`, `notification_preferences`

**ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
- Telegram ë©”ì‹œì§€ ë°œì†¡ (Celery ì›Œì»¤)
- ì•Œë¦¼ ì¬ì‹œë„ ë¡œì§

**ë°°í¬**:
- ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” ì•¡í‹°ë¸Œ-ìŠ¤íƒ ë°”ì´

**í¬íŠ¸**: 8007

---

##### 8. **User & Account Service** ğŸ‘¤

**ì±…ì„**:
- ì‚¬ìš©ì ì¸ì¦/ì¸ê°€
- ê±°ë˜ì†Œ API í‚¤ ê´€ë¦¬
- ì‚¬ìš©ì ì„¤ì • ê´€ë¦¬
- ê¶Œí•œ ê´€ë¦¬

**API ì—”ë“œí¬ì¸íŠ¸**:
```
POST   /api/users/register
POST   /api/users/login
GET    /api/users/profile/{user_id}
POST   /api/users/credentials
GET    /api/users/settings/{user_id}
PUT    /api/users/settings/{user_id}
```

**ë°ì´í„° ì†Œìœ **:
- PostgreSQL: `users`, `user_credentials`, `user_settings`
- Redis: `session:{session_id}` (ì„¸ì…˜)

**ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**:
- ì„¸ì…˜ í´ë¦¬ë‹ (Celery Beat)

**ë°°í¬**:
- ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ (ì½ê¸° ë³µì œë³¸)

**í¬íŠ¸**: 8008

---

##### 9. **Configuration Service** âš™ï¸

**ì±…ì„**:
- ì¤‘ì•™ ì„¤ì • ê´€ë¦¬
- Feature flags
- ë™ì  ì„¤ì • ì—…ë°ì´íŠ¸
- ì„¤ì • ë²„ì „ ê´€ë¦¬

**API ì—”ë“œí¬ì¸íŠ¸**:
```
GET    /api/config/{service}/{key}
POST   /api/config/{service}/{key}
GET    /api/config/features
POST   /api/config/features/{flag}
```

**ë°ì´í„° ì†Œìœ **:
- PostgreSQL: `service_config`, `feature_flags`
- Redis: ì„¤ì • ìºì‹œ

**ë°°í¬**:
- ê³ ê°€ìš©ì„± (3+ ì¸ìŠ¤í„´ìŠ¤)

**í¬íŠ¸**: 8009

---

##### 10. **Analytics & Logging Service** ğŸ“Š

**ì±…ì„**:
- ì¤‘ì•™ ë¡œê·¸ ìˆ˜ì§‘
- ë©”íŠ¸ë¦­ ì§‘ê³„
- ëŒ€ì‹œë³´ë“œ API
- ê±°ë˜ ì„±ê³¼ ë¶„ì„

**API ì—”ë“œí¬ì¸íŠ¸**:
```
POST   /api/logs/ingest
GET    /api/analytics/performance/{user_id}
GET    /api/analytics/metrics/{service}
GET    /api/analytics/dashboard
```

**ë°ì´í„° ì†Œìœ **:
- Elasticsearch/Loki: ë¡œê·¸ ì €ì¥
- InfluxDB/TimescaleDB: ì‹œê³„ì—´ ë©”íŠ¸ë¦­
- PostgreSQL: ì§‘ê³„ëœ ë¶„ì„ ë°ì´í„°

**ë°°í¬**:
- ë³„ë„ ì¸í”„ë¼ (ELK ìŠ¤íƒ ë˜ëŠ” Grafana Loki)

**í¬íŠ¸**: 8010

---

### 2.3 ì„œë¹„ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    subgraph "Client Layer"
        WEB[Web Frontend]
        MOB[Mobile App]
        TG[Telegram Bot]
    end

    subgraph "API Gateway"
        GW[Kong/Traefik/NGINX]
    end

    subgraph "Core Trading Services"
        HYPER[HYPERRSI Service:8001]
        GRID[GRID Service:8002]
        MARKET[Market Data:8003]
        OMS[Order Management:8004]
        EXCH[Exchange Gateway:8005]
        POS[Position Management:8006]
    end

    subgraph "Supporting Services"
        NOTIF[Notification:8007]
        USER[User & Account:8008]
        CONFIG[Configuration:8009]
        ANALYTICS[Analytics:8010]
    end

    subgraph "Infrastructure"
        REDIS[(Redis Cluster)]
        PG[(PostgreSQL)]
        KAFKA[Kafka/Redis Streams]
        ELASTIC[(Elasticsearch)]
    end

    WEB --> GW
    MOB --> GW
    TG --> NOTIF

    GW --> HYPER
    GW --> GRID
    GW --> OMS
    GW --> POS
    GW --> USER

    HYPER --> MARKET
    HYPER --> OMS
    HYPER --> CONFIG

    GRID --> MARKET
    GRID --> OMS
    GRID --> CONFIG

    OMS --> EXCH
    OMS --> POS
    OMS --> KAFKA

    MARKET --> KAFKA
    MARKET --> REDIS

    EXCH --> REDIS
    EXCH --> PG

    POS --> REDIS
    POS --> PG

    HYPER --> REDIS
    GRID --> REDIS

    HYPER --> PG
    GRID --> PG

    NOTIF --> PG
    USER --> PG
    CONFIG --> PG

    ANALYTICS --> ELASTIC
    ANALYTICS --> PG

    All --> KAFKA
```

---

## 3. ì„œë¹„ìŠ¤ ê°„ í†µì‹  íŒ¨í„´

### 3.1 í†µì‹  í”„ë¡œí† ì½œ ì„ íƒ

#### A. REST API (ë™ê¸° í†µì‹ )

**ì‚¬ìš© ì‚¬ë¡€**:
- ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ (CRUD ì‘ì—…)
- ì„œë¹„ìŠ¤ ê°„ ì§ì ‘ í˜¸ì¶œ (ê°„ë‹¨í•œ ì¿¼ë¦¬)

**êµ¬í˜„**:
```python
# httpxë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸
from httpx import AsyncClient
from typing import Any

class ServiceClient:
    def __init__(self, base_url: str, timeout: float = 30.0):
        self.client = AsyncClient(
            base_url=base_url,
            timeout=timeout,
            limits=httpx.Limits(max_connections=100)
        )

    async def get(self, endpoint: str, **kwargs) -> Any:
        response = await self.client.get(endpoint, **kwargs)
        response.raise_for_status()
        return response.json()

    async def post(self, endpoint: str, **kwargs) -> Any:
        response = await self.client.post(endpoint, **kwargs)
        response.raise_for_status()
        return response.json()

# ì‚¬ìš© ì˜ˆì‹œ
market_client = ServiceClient("http://market-data-service:8003")
ticker = await market_client.get("/api/market/ticker/okx/BTC-USDT-SWAP")
```

**ì¥ì **:
- ê°„ë‹¨í•˜ê³  ì§ê´€ì 
- ë””ë²„ê¹… ìš©ì´
- HTTP í‘œì¤€ í™œìš©

**ë‹¨ì **:
- ë™ê¸°ì  ê²°í•©
- ì„œë¹„ìŠ¤ ì¥ì•  ì „íŒŒ
- ë„¤íŠ¸ì›Œí¬ ì§€ì—°

---

#### B. gRPC (ê³ ì„±ëŠ¥ ë™ê¸° í†µì‹ )

**ì‚¬ìš© ì‚¬ë¡€**:
- ì„œë¹„ìŠ¤ ê°„ ê³ ë¹ˆë„ í˜¸ì¶œ (ë‚´ë¶€ í†µì‹ )
- ì €ì§€ì—° ìš”êµ¬ì‚¬í•­ (ì£¼ë¬¸ ì‹¤í–‰)

**êµ¬í˜„**:
```python
# order_service.proto
syntax = "proto3";

service OrderService {
  rpc CreateOrder(CreateOrderRequest) returns (CreateOrderResponse);
  rpc CancelOrder(CancelOrderRequest) returns (CancelOrderResponse);
  rpc GetOrderStatus(GetOrderStatusRequest) returns (Order);
}

message CreateOrderRequest {
  string user_id = 1;
  string symbol = 2;
  string side = 3;
  double quantity = 4;
  double price = 5;
}

message CreateOrderResponse {
  string order_id = 1;
  string status = 2;
}

# order_client.py
import grpc
from proto import order_service_pb2, order_service_pb2_grpc

async def create_order(user_id: str, symbol: str, side: str, qty: float, price: float):
    async with grpc.aio.insecure_channel('order-service:50051') as channel:
        stub = order_service_pb2_grpc.OrderServiceStub(channel)
        request = order_service_pb2.CreateOrderRequest(
            user_id=user_id, symbol=symbol, side=side,
            quantity=qty, price=price
        )
        response = await stub.CreateOrder(request)
        return response.order_id
```

**ì¥ì **:
- ê³ ì„±ëŠ¥ (Protocol Buffers)
- íƒ€ì… ì•ˆì „ì„±
- ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›

**ë‹¨ì **:
- í•™ìŠµ ê³¡ì„ 
- HTTP/2 ì¸í”„ë¼ í•„ìš”
- ë””ë²„ê¹… ë³µì¡ë„

---

#### C. ë©”ì‹œì§€ í (ë¹„ë™ê¸° í†µì‹ )

**ì‚¬ìš© ì‚¬ë¡€**:
- ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜
- ëŠìŠ¨í•œ ê²°í•© í•„ìš”
- ì‘ì—… í

**ì˜µì…˜ 1: Redis Streams**

```python
# ì´ë²¤íŠ¸ ë°œí–‰ì (OMS)
import redis.asyncio as aioredis

async def publish_order_filled_event(order_id: str, fill_data: dict):
    redis_client = await aioredis.from_url("redis://localhost:6379")

    event = {
        "order_id": order_id,
        "user_id": fill_data["user_id"],
        "symbol": fill_data["symbol"],
        "filled_qty": fill_data["filled_qty"],
        "fill_price": fill_data["fill_price"],
        "timestamp": time.time()
    }

    await redis_client.xadd(
        "events:order_filled",
        event,
        maxlen=10000  # ìµœëŒ€ 10K ì´ë²¤íŠ¸ ìœ ì§€
    )

# ì´ë²¤íŠ¸ ì†Œë¹„ì (Position Service)
async def consume_order_events():
    redis_client = await aioredis.from_url("redis://localhost:6379")
    last_id = '0-0'

    while True:
        events = await redis_client.xread(
            {"events:order_filled": last_id},
            count=10,
            block=1000  # 1ì´ˆ ëŒ€ê¸°
        )

        for stream, messages in events:
            for message_id, data in messages:
                await process_fill_event(data)
                last_id = message_id
```

**ì¥ì **:
- Redis ê¸°ì¡´ ì¸í”„ë¼ í™œìš©
- ê°„ë‹¨í•œ êµ¬í˜„
- ë‚®ì€ ì§€ì—°

**ë‹¨ì **:
- ë©”ì‹œì§€ ë³´ì¦ ìˆ˜ì¤€ ë‚®ìŒ
- ë³µì¡í•œ ë¼ìš°íŒ… ì–´ë ¤ì›€

**ì˜µì…˜ 2: Apache Kafka**

```python
from aiokafka import AIOKafkaProducer, AIOKafkaConsumer
import json

# í”„ë¡œë“€ì„œ
async def publish_to_kafka(topic: str, event: dict):
    producer = AIOKafkaProducer(
        bootstrap_servers='kafka:9092',
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )
    await producer.start()
    try:
        await producer.send_and_wait(topic, event)
    finally:
        await producer.stop()

# ì»¨ìŠˆë¨¸
async def consume_from_kafka(topic: str, group_id: str):
    consumer = AIOKafkaConsumer(
        topic,
        bootstrap_servers='kafka:9092',
        group_id=group_id,
        value_deserializer=lambda m: json.loads(m.decode('utf-8'))
    )
    await consumer.start()
    try:
        async for msg in consumer:
            await process_message(msg.value)
    finally:
        await consumer.stop()
```

**ì¥ì **:
- ë†’ì€ ì²˜ë¦¬ëŸ‰
- ë©”ì‹œì§€ ì˜ì†ì„±
- ë³µì¡í•œ ì´ë²¤íŠ¸ ì²˜ë¦¬

**ë‹¨ì **:
- ìš´ì˜ ë³µì¡ë„ ë†’ìŒ
- ì¶”ê°€ ì¸í”„ë¼ í•„ìš”
- ì˜¤ë²„í‚¬ ê°€ëŠ¥ì„±

---

### 3.2 í†µì‹  íŒ¨í„´ ê¶Œì¥ì‚¬í•­

| ì‹œë‚˜ë¦¬ì˜¤ | ê¶Œì¥ í”„ë¡œí† ì½œ | ì´ìœ  |
|---------|-------------|------|
| ì‚¬ìš©ì API í˜¸ì¶œ â†’ ì„œë¹„ìŠ¤ | REST (FastAPI) | í‘œì¤€, ê°„ë‹¨í•¨ |
| Strategy â†’ OMS ì£¼ë¬¸ ìƒì„± | gRPC | ì €ì§€ì—°, ê³ ë¹ˆë„ |
| OMS â†’ Position ìƒíƒœ ì—…ë°ì´íŠ¸ | Redis Streams | ë¹„ë™ê¸°, ë¹ ë¦„ |
| Market Data â†’ Strategies ê°€ê²© í‘¸ì‹œ | Redis Streams | ì‹¤ì‹œê°„, ë‹¤ìˆ˜ êµ¬ë…ì |
| Notification ì•Œë¦¼ í | Celery (Redis) | ê¸°ì¡´ ì¸í”„ë¼ |
| ì„œë¹„ìŠ¤ ê°„ ì„¤ì • ì¡°íšŒ | REST (ìºì‹œ) | ì½ê¸° ì¤‘ì‹¬ |

---

### 3.3 API ê³„ì•½ ì˜ˆì‹œ

#### OMS API ê³„ì•½ (OpenAPI/Swagger)

```yaml
openapi: 3.0.0
info:
  title: Order Management Service
  version: 1.0.0

paths:
  /api/orders/create:
    post:
      summary: Create a new order
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                user_id:
                  type: string
                symbol:
                  type: string
                side:
                  type: string
                  enum: [buy, sell]
                order_type:
                  type: string
                  enum: [market, limit, stop]
                quantity:
                  type: number
                price:
                  type: number
                  nullable: true
      responses:
        '201':
          description: Order created
          content:
            application/json:
              schema:
                type: object
                properties:
                  order_id:
                    type: string
                  status:
                    type: string
                  created_at:
                    type: string
                    format: date-time
```

#### ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ (Redis Streams)

```python
from pydantic import BaseModel
from datetime import datetime

class OrderFilledEvent(BaseModel):
    event_type: str = "order.filled"
    order_id: str
    user_id: str
    symbol: str
    side: str
    filled_qty: float
    fill_price: float
    commission: float
    timestamp: datetime
```

---

## 4. ë°ì´í„° ê´€ë¦¬ ì „ëµ

### 4.1 Database per Service íŒ¨í„´

**ì›ì¹™**: ê° ì„œë¹„ìŠ¤ëŠ” ìì‹ ì˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì†Œìœ í•˜ë©°, ë‹¤ë¥¸ ì„œë¹„ìŠ¤ëŠ” APIë¥¼ í†µí•´ì„œë§Œ ì ‘ê·¼

#### PostgreSQL ìŠ¤í‚¤ë§ˆ ë¶„ë¦¬

```sql
-- HYPERRSI Service ì „ìš© ìŠ¤í‚¤ë§ˆ
CREATE SCHEMA hyperrsi;

CREATE TABLE hyperrsi.signals (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL,
    symbol VARCHAR(20) NOT NULL,
    timeframe VARCHAR(10) NOT NULL,
    signal_type VARCHAR(10),  -- buy, sell
    rsi_value DECIMAL(5,2),
    trend_direction VARCHAR(10),
    created_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_user_symbol (user_id, symbol)
);

CREATE TABLE hyperrsi.state (
    user_id VARCHAR(50) PRIMARY KEY,
    symbol VARCHAR(20),
    is_active BOOLEAN DEFAULT FALSE,
    last_execution TIMESTAMP,
    settings JSONB
);

-- GRID Service ì „ìš© ìŠ¤í‚¤ë§ˆ
CREATE SCHEMA grid;

CREATE TABLE grid.levels (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL,
    symbol VARCHAR(20) NOT NULL,
    grid_index INT NOT NULL,
    price DECIMAL(18,8) NOT NULL,
    order_id VARCHAR(50),
    status VARCHAR(20),  -- pending, filled, cancelled
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(user_id, symbol, grid_index)
);

-- OMS ì „ìš© ìŠ¤í‚¤ë§ˆ
CREATE SCHEMA oms;

CREATE TABLE oms.orders (
    order_id VARCHAR(50) PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL,
    symbol VARCHAR(20) NOT NULL,
    side VARCHAR(10) NOT NULL,
    order_type VARCHAR(20),
    quantity DECIMAL(18,8),
    price DECIMAL(18,8),
    filled_qty DECIMAL(18,8) DEFAULT 0,
    status VARCHAR(20),  -- pending, filled, cancelled, failed
    exchange VARCHAR(20),
    exchange_order_id VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_user_orders (user_id, created_at DESC)
);

CREATE TABLE oms.order_fills (
    id SERIAL PRIMARY KEY,
    order_id VARCHAR(50) REFERENCES oms.orders(order_id),
    fill_qty DECIMAL(18,8),
    fill_price DECIMAL(18,8),
    commission DECIMAL(18,8),
    fill_time TIMESTAMP,
    exchange_fill_id VARCHAR(100)
);
```

---

### 4.2 Redis í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì „ëµ

**íŒ¨í„´**: `{service}:{domain}:{identifier}:{attribute}`

```python
# Redis í‚¤ ìŠ¤í‚¤ë§ˆ ì •ì˜ (ê° ì„œë¹„ìŠ¤ë³„)

# HYPERRSI Service
HYPERRSI_KEYS = {
    "status": "hyperrsi:status:{user_id}:{symbol}",
    "signal": "hyperrsi:signal:{user_id}:{symbol}:latest",
    "lock": "hyperrsi:lock:{user_id}:{symbol}:{timeframe}",
}

# GRID Service
GRID_KEYS = {
    "levels": "grid:levels:{user_id}:{symbol}",
    "state": "grid:state:{user_id}:{symbol}",
    "orders": "grid:orders:{user_id}:{symbol}",
}

# OMS
OMS_KEYS = {
    "order": "oms:order:{order_id}",
    "user_orders": "oms:user:{user_id}:orders",  # Sorted Set
    "pending": "oms:pending:{exchange}",  # List
}

# Market Data
MARKET_KEYS = {
    "ticker": "market:ticker:{exchange}:{symbol}",
    "orderbook": "market:orderbook:{exchange}:{symbol}",
    "candle": "market:candle:{exchange}:{symbol}:{timeframe}",
}

# Position Management
POSITION_KEYS = {
    "position": "position:{user_id}:{symbol}",
    "pnl": "position:pnl:{user_id}:{symbol}",
}
```

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
from typing import Optional
import redis.asyncio as aioredis

class RedisKeyManager:
    def __init__(self, service_name: str):
        self.service_name = service_name
        self.redis = aioredis.from_url("redis://localhost:6379")

    def key(self, pattern: str, **kwargs) -> str:
        """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ í¬í•¨í•œ í‚¤ ìƒì„±"""
        return f"{self.service_name}:{pattern.format(**kwargs)}"

    async def set_with_ttl(self, pattern: str, value: str, ttl: int, **kwargs):
        key = self.key(pattern, **kwargs)
        await self.redis.setex(key, ttl, value)

    async def get(self, pattern: str, **kwargs) -> Optional[str]:
        key = self.key(pattern, **kwargs)
        return await self.redis.get(key)

# ì‚¬ìš© ì˜ˆì‹œ
hyperrsi_redis = RedisKeyManager("hyperrsi")
await hyperrsi_redis.set_with_ttl(
    "status:{user_id}:{symbol}",
    "active",
    ttl=3600,
    user_id="user123",
    symbol="BTC-USDT-SWAP"
)
```

---

### 4.3 ê³µìœ  ë°ì´í„° ì²˜ë¦¬

#### ë¬¸ì œ: ì—¬ëŸ¬ ì„œë¹„ìŠ¤ê°€ ë™ì¼í•œ ë°ì´í„° í•„ìš” (ì˜ˆ: ì‚¬ìš©ì ì •ë³´)

**ì•ˆí‹°íŒ¨í„´**: ì§ì ‘ ë°ì´í„°ë² ì´ìŠ¤ ê³µìœ  âŒ

```python
# ë‚˜ìœ ì˜ˆ: ì—¬ëŸ¬ ì„œë¹„ìŠ¤ê°€ users í…Œì´ë¸” ì§ì ‘ ì ‘ê·¼
# HYPERRSI Service
user = db.query("SELECT * FROM users WHERE user_id = ?", user_id)

# GRID Service
user = db.query("SELECT * FROM users WHERE user_id = ?", user_id)
```

**íŒ¨í„´ 1: API í˜¸ì¶œë¡œ ë°ì´í„° ì¡°íšŒ** âœ…

```python
# HYPERRSI Service
async def get_user_info(user_id: str) -> dict:
    async with httpx.AsyncClient() as client:
        response = await client.get(f"http://user-service:8008/api/users/{user_id}")
        return response.json()

# ìºì‹± ì¶”ê°€
from functools import lru_cache
from cachetools import TTLCache
import asyncio

user_cache = TTLCache(maxsize=1000, ttl=300)  # 5ë¶„ ìºì‹œ

async def get_user_info_cached(user_id: str) -> dict:
    if user_id in user_cache:
        return user_cache[user_id]

    user_info = await get_user_info(user_id)
    user_cache[user_id] = user_info
    return user_info
```

**íŒ¨í„´ 2: ì´ë²¤íŠ¸ ê¸°ë°˜ ë°ì´í„° ë³µì œ** âœ…

```python
# User Service: ì‚¬ìš©ì ì •ë³´ ë³€ê²½ ì‹œ ì´ë²¤íŠ¸ ë°œí–‰
async def update_user_settings(user_id: str, settings: dict):
    # DB ì—…ë°ì´íŠ¸
    await db.execute("UPDATE users SET settings = ? WHERE user_id = ?", settings, user_id)

    # ì´ë²¤íŠ¸ ë°œí–‰
    event = {
        "event_type": "user.settings_updated",
        "user_id": user_id,
        "settings": settings,
        "timestamp": time.time()
    }
    await redis_client.xadd("events:user_updates", event)

# HYPERRSI Service: ì´ë²¤íŠ¸ ì†Œë¹„í•˜ì—¬ ë¡œì»¬ ìºì‹œ ì—…ë°ì´íŠ¸
async def sync_user_settings():
    async for event in consume_user_events():
        if event["event_type"] == "user.settings_updated":
            user_cache[event["user_id"]] = event["settings"]
```

---

### 4.4 ë¶„ì‚° íŠ¸ëœì­ì…˜ ì²˜ë¦¬

#### ë¬¸ì œ: ì—¬ëŸ¬ ì„œë¹„ìŠ¤ì— ê±¸ì¹œ ì¼ê´€ì„± ë³´ì¥ (ì˜ˆ: ì£¼ë¬¸ ìƒì„± + í¬ì§€ì…˜ ì—…ë°ì´íŠ¸)

**íŒ¨í„´: Saga íŒ¨í„´** (Orchestration ë°©ì‹)

```python
# OMSì—ì„œ ì£¼ë¬¸ ìƒì„± Saga ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
from enum import Enum
from typing import List, Callable, Any

class SagaStep:
    def __init__(
        self,
        name: str,
        action: Callable,
        compensation: Callable
    ):
        self.name = name
        self.action = action
        self.compensation = compensation

class SagaOrchestrator:
    def __init__(self):
        self.steps: List[SagaStep] = []
        self.executed_steps: List[str] = []

    def add_step(self, step: SagaStep):
        self.steps.append(step)

    async def execute(self) -> bool:
        try:
            for step in self.steps:
                logger.info(f"Executing saga step: {step.name}")
                await step.action()
                self.executed_steps.append(step.name)
            return True
        except Exception as e:
            logger.error(f"Saga failed at step {step.name}: {e}")
            await self.compensate()
            return False

    async def compensate(self):
        """ì‹¤íŒ¨ ì‹œ ë³´ìƒ íŠ¸ëœì­ì…˜ ì‹¤í–‰ (ì—­ìˆœ)"""
        for step_name in reversed(self.executed_steps):
            step = next(s for s in self.steps if s.name == step_name)
            try:
                logger.info(f"Compensating: {step.name}")
                await step.compensation()
            except Exception as e:
                logger.error(f"Compensation failed for {step.name}: {e}")

# ì£¼ë¬¸ ìƒì„± Saga ì˜ˆì‹œ
async def create_order_saga(user_id: str, symbol: str, side: str, qty: float, price: float):
    order_id = None

    async def reserve_balance():
        nonlocal order_id
        # 1. ì”ê³  í™•ì¸ ë° ì˜ˆì•½
        response = await exchange_gateway_client.post(
            "/api/exchange/reserve_balance",
            json={"user_id": user_id, "amount": qty * price}
        )
        if not response.get("success"):
            raise Exception("Insufficient balance")

    async def unreserve_balance():
        await exchange_gateway_client.post(
            "/api/exchange/unreserve_balance",
            json={"user_id": user_id, "amount": qty * price}
        )

    async def create_order_record():
        nonlocal order_id
        # 2. OMSì— ì£¼ë¬¸ ê¸°ë¡ ìƒì„±
        order_id = await db.execute(
            "INSERT INTO orders (...) VALUES (...)",
            user_id, symbol, side, qty, price
        )

    async def delete_order_record():
        await db.execute("DELETE FROM orders WHERE order_id = ?", order_id)

    async def submit_to_exchange():
        # 3. ê±°ë˜ì†Œì— ì‹¤ì œ ì£¼ë¬¸ ì œì¶œ
        response = await exchange_gateway_client.post(
            "/api/exchange/execute",
            json={
                "user_id": user_id,
                "exchange": "okx",
                "action": "create_order",
                "params": {"symbol": symbol, "side": side, "qty": qty, "price": price}
            }
        )
        if not response.get("success"):
            raise Exception("Exchange order failed")

    async def cancel_exchange_order():
        await exchange_gateway_client.post(
            "/api/exchange/execute",
            json={
                "action": "cancel_order",
                "order_id": order_id
            }
        )

    async def update_position():
        # 4. í¬ì§€ì…˜ ì„œë¹„ìŠ¤ì— ì•Œë¦¼
        await position_client.post(
            "/api/positions/update_pending",
            json={"order_id": order_id, "user_id": user_id, "symbol": symbol}
        )

    async def rollback_position():
        await position_client.post(
            "/api/positions/rollback_pending",
            json={"order_id": order_id}
        )

    # Saga êµ¬ì„±
    saga = SagaOrchestrator()
    saga.add_step(SagaStep("reserve_balance", reserve_balance, unreserve_balance))
    saga.add_step(SagaStep("create_order", create_order_record, delete_order_record))
    saga.add_step(SagaStep("submit_exchange", submit_to_exchange, cancel_exchange_order))
    saga.add_step(SagaStep("update_position", update_position, rollback_position))

    success = await saga.execute()
    return {"success": success, "order_id": order_id if success else None}
```

**ì¥ì **:
- ë¶„ì‚° íŠ¸ëœì­ì…˜ ì¼ê´€ì„± ë³´ì¥
- ì‹¤íŒ¨ ì‹œ ìë™ ë¡¤ë°±
- ëª…ì‹œì ì¸ ë³´ìƒ ë¡œì§

**ë‹¨ì **:
- ë³µì¡ë„ ì¦ê°€
- ë³´ìƒ íŠ¸ëœì­ì…˜ ì„¤ê³„ ì–´ë ¤ì›€
- ìµœì¢… ì¼ê´€ì„± (Eventual Consistency)

---

### 4.5 ìºì‹± ì „ëµ

**ë‹¤ì¸µ ìºì‹œ ì•„í‚¤í…ì²˜**:

```
[Application Memory Cache] â†’ [Redis Cache] â†’ [PostgreSQL]
     (L1: 1ì´ˆ TTL)         (L2: 60ì´ˆ TTL)    (ì˜êµ¬ ì €ì¥)
```

**êµ¬í˜„**:
```python
from cachetools import TTLCache
import redis.asyncio as aioredis
from typing import Optional, Any
import json
import asyncio

class MultiLevelCache:
    def __init__(self):
        # L1: ë©”ëª¨ë¦¬ ìºì‹œ (ë§¤ìš° ë¹ ë¦„, ì‘ì€ ìš©ëŸ‰)
        self.l1_cache = TTLCache(maxsize=1000, ttl=1)

        # L2: Redis ìºì‹œ (ë¹ ë¦„, ì¤‘ê°„ ìš©ëŸ‰)
        self.l2_cache = aioredis.from_url("redis://localhost:6379")
        self.l2_ttl = 60

    async def get(self, key: str) -> Optional[Any]:
        # L1 ìºì‹œ í™•ì¸
        if key in self.l1_cache:
            return self.l1_cache[key]

        # L2 ìºì‹œ í™•ì¸
        value = await self.l2_cache.get(key)
        if value:
            deserialized = json.loads(value)
            self.l1_cache[key] = deserialized  # L1ì— ì €ì¥
            return deserialized

        return None

    async def set(self, key: str, value: Any):
        # L1, L2 ë™ì‹œ ì €ì¥
        self.l1_cache[key] = value
        await self.l2_cache.setex(key, self.l2_ttl, json.dumps(value))

    async def invalidate(self, key: str):
        # ëª¨ë“  ë ˆë²¨ì—ì„œ ì‚­ì œ
        self.l1_cache.pop(key, None)
        await self.l2_cache.delete(key)

# ì‚¬ìš© ì˜ˆì‹œ: ë§ˆì¼“ ë°ì´í„° ì¡°íšŒ
cache = MultiLevelCache()

async def get_ticker(exchange: str, symbol: str) -> dict:
    cache_key = f"ticker:{exchange}:{symbol}"

    # ìºì‹œ í™•ì¸
    cached = await cache.get(cache_key)
    if cached:
        return cached

    # DBì—ì„œ ì¡°íšŒ
    ticker = await db.fetch_one(
        "SELECT * FROM market_tickers WHERE exchange = ? AND symbol = ?",
        exchange, symbol
    )

    # ìºì‹œì— ì €ì¥
    await cache.set(cache_key, ticker)
    return ticker
```

---

## 5. ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡œë“œë§µ

### 5.1 ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ (Strangler Fig Pattern)

**ì›ì¹™**: ê¸°ì¡´ ëª¨ë…¸ë¦¬ìŠ¤ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì ì§„ì ìœ¼ë¡œ ì„œë¹„ìŠ¤ ë¶„ë¦¬

```mermaid
gantt
    title ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡œë“œë§µ
    dateFormat  YYYY-MM-DD
    section Phase 1: ì¸í”„ë¼ ì¤€ë¹„
    API Gateway êµ¬ì¶•           :p1-1, 2025-11-01, 14d
    Redis Cluster êµ¬ì¶•         :p1-2, 2025-11-08, 7d
    PostgreSQL ìƒ¤ë”© ì„¤ê³„       :p1-3, 2025-11-15, 7d
    CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•      :p1-4, 2025-11-22, 14d

    section Phase 2: ì²« ë²ˆì§¸ ì„œë¹„ìŠ¤ ë¶„ë¦¬
    Notification Service ë¶„ë¦¬  :p2-1, 2025-12-01, 14d
    User Service ë¶„ë¦¬          :p2-2, 2025-12-15, 21d

    section Phase 3: í•µì‹¬ ì„œë¹„ìŠ¤ ë¶„ë¦¬
    Market Data Service ë¶„ë¦¬   :p3-1, 2026-01-05, 28d
    Exchange Gateway ë¶„ë¦¬      :p3-2, 2026-02-02, 28d

    section Phase 4: ê±°ë˜ ì„œë¹„ìŠ¤ ë¶„ë¦¬
    OMS ë¶„ë¦¬                   :p4-1, 2026-03-01, 35d
    Position Service ë¶„ë¦¬      :p4-2, 2026-04-05, 28d

    section Phase 5: ì „ëµ ì„œë¹„ìŠ¤ ë¶„ë¦¬
    HYPERRSI Service ë¶„ë¦¬      :p5-1, 2026-05-01, 42d
    GRID Service ë¶„ë¦¬          :p5-2, 2026-06-12, 42d

    section Phase 6: ìµœì í™” ë° ì•ˆì •í™”
    ì„±ëŠ¥ ìµœì í™”                :p6-1, 2026-07-24, 21d
    ëª¨ë‹ˆí„°ë§ ê°•í™”              :p6-2, 2026-08-14, 14d
    ëª¨ë…¸ë¦¬ìŠ¤ íê¸°              :p6-3, 2026-08-28, 7d
```

---

### 5.2 Phase 1: ì¸í”„ë¼ ì¤€ë¹„ (2ì£¼)

**ëª©í‘œ**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ìš´ì˜ì— í•„ìš”í•œ ê¸°ë°˜ ì¸í”„ë¼ êµ¬ì¶•

#### 1.1 API Gateway êµ¬ì¶•

**ë„êµ¬ ì„ íƒ**: Kong, Traefik, ë˜ëŠ” NGINX + Lua

**Kong ê¸°ë°˜ ì˜ˆì‹œ**:
```yaml
# docker-compose.yml
services:
  kong-database:
    image: postgres:15
    environment:
      POSTGRES_DB: kong
      POSTGRES_USER: kong
      POSTGRES_PASSWORD: kong
    volumes:
      - kong-db:/var/lib/postgresql/data

  kong-migration:
    image: kong:3.4
    command: kong migrations bootstrap
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-database
    depends_on:
      - kong-database

  kong:
    image: kong:3.4
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-database
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
    ports:
      - "8000:8000"   # Proxy HTTP
      - "8443:8443"   # Proxy HTTPS
      - "8001:8001"   # Admin API
    depends_on:
      - kong-migration
```

**ë¼ìš°íŒ… ì„¤ì •**:
```bash
# HYPERRSI ì„œë¹„ìŠ¤ ë“±ë¡
curl -i -X POST http://localhost:8001/services/ \
  --data "name=hyperrsi-service" \
  --data "url=http://hyperrsi:8001"

# ë¼ìš°íŠ¸ ì¶”ê°€
curl -i -X POST http://localhost:8001/services/hyperrsi-service/routes \
  --data "paths[]=/api/strategy/hyperrsi"

# Rate limiting í”ŒëŸ¬ê·¸ì¸
curl -i -X POST http://localhost:8001/services/hyperrsi-service/plugins \
  --data "name=rate-limiting" \
  --data "config.minute=100"
```

#### 1.2 Redis Cluster êµ¬ì¶•

**Redis Sentinel êµ¬ì„±** (ê³ ê°€ìš©ì„±):
```yaml
# docker-compose.yml
services:
  redis-master:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-master-data:/data

  redis-replica-1:
    image: redis:7-alpine
    command: redis-server --appendonly yes --slaveof redis-master 6379
    depends_on:
      - redis-master

  redis-replica-2:
    image: redis:7-alpine
    command: redis-server --appendonly yes --slaveof redis-master 6379
    depends_on:
      - redis-master

  redis-sentinel-1:
    image: redis:7-alpine
    command: >
      redis-server /etc/redis/sentinel.conf --sentinel
    volumes:
      - ./sentinel.conf:/etc/redis/sentinel.conf

  redis-sentinel-2:
    image: redis:7-alpine
    command: >
      redis-server /etc/redis/sentinel.conf --sentinel
    volumes:
      - ./sentinel.conf:/etc/redis/sentinel.conf

  redis-sentinel-3:
    image: redis:7-alpine
    command: >
      redis-server /etc/redis/sentinel.conf --sentinel
    volumes:
      - ./sentinel.conf:/etc/redis/sentinel.conf
```

**sentinel.conf**:
```
port 26379
sentinel monitor mymaster redis-master 6379 2
sentinel down-after-milliseconds mymaster 5000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 10000
```

#### 1.3 CI/CD íŒŒì´í”„ë¼ì¸

**GitHub Actions ì˜ˆì‹œ**:
```yaml
# .github/workflows/deploy-service.yml
name: Deploy Microservice

on:
  push:
    branches: [main]
    paths:
      - 'services/hyperrsi/**'

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Build Docker image
        run: |
          docker build -t hyperrsi-service:${{ github.sha }} \
            -f services/hyperrsi/Dockerfile .

      - name: Push to registry
        run: |
          echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
          docker push hyperrsi-service:${{ github.sha }}

      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/hyperrsi-service \
            hyperrsi=hyperrsi-service:${{ github.sha }}
```

---

### 5.3 Phase 2: ì²« ë²ˆì§¸ ì„œë¹„ìŠ¤ ë¶„ë¦¬ (3ì£¼)

**ëª©í‘œ**: ì˜ì¡´ì„±ì´ ë‚®ì€ ì„œë¹„ìŠ¤ë¶€í„° ë¶„ë¦¬í•˜ì—¬ ê²½í—˜ ì¶•ì 

#### 2.1 Notification Service ë¶„ë¦¬ (2ì£¼)

**ì™œ ë¨¼ì €?**:
- ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì— ì˜ì¡´ì„± ê±°ì˜ ì—†ìŒ (ë‹¨ë°©í–¥)
- ì‹¤íŒ¨í•´ë„ í•µì‹¬ ê±°ë˜ì— ì˜í–¥ ì—†ìŒ
- í…ŒìŠ¤íŠ¸ ìš©ì´

**ë‹¨ê³„**:

1. **ìƒˆ ì €ì¥ì†Œ ìƒì„±**
```bash
mkdir services/notification-service
cd services/notification-service
```

2. **ê¸°ì¡´ ì½”ë“œ ë³µì‚¬ ë° ë¦¬íŒ©í„°ë§**
```python
# services/notification-service/main.py
from fastapi import FastAPI
from pydantic import BaseModel
from telegram import Bot
import redis.asyncio as aioredis

app = FastAPI(title="Notification Service")

class NotificationRequest(BaseModel):
    user_id: str
    message: str
    priority: str = "normal"

telegram_bot = Bot(token=os.getenv("TELEGRAM_BOT_TOKEN"))
redis_client = None

@app.on_event("startup")
async def startup():
    global redis_client
    redis_client = await aioredis.from_url("redis://redis:6379")

@app.post("/api/notifications/send")
async def send_notification(req: NotificationRequest):
    # Redis íì— ì¶”ê°€
    await redis_client.lpush(
        f"notification:queue:{req.priority}",
        json.dumps(req.dict())
    )
    return {"status": "queued"}

# Celery ì›Œì»¤ (ë³„ë„ í”„ë¡œì„¸ìŠ¤)
from celery import Celery
celery_app = Celery('notification', broker='redis://redis:6379/1')

@celery_app.task
def process_notification_queue():
    # íì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì™€ì„œ ë°œì†¡
    pass
```

3. **Dockerfile ì‘ì„±**
```dockerfile
FROM python:3.12-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8007"]
```

4. **ê¸°ì¡´ ì½”ë“œì—ì„œ í˜¸ì¶œ ë³€ê²½**
```python
# Before (HYPERRSI/src/bot/telegram_message.py)
from shared.notifications.telegram import send_telegram_message

await send_telegram_message(user_id, message)

# After
import httpx

async def send_telegram_message(user_id: str, message: str):
    async with httpx.AsyncClient() as client:
        await client.post(
            "http://notification-service:8007/api/notifications/send",
            json={"user_id": user_id, "message": message}
        )
```

5. **ë°°í¬ ë° ê²€ì¦**
```bash
docker-compose up -d notification-service
curl http://localhost:8007/api/notifications/send \
  -H "Content-Type: application/json" \
  -d '{"user_id": "test", "message": "Hello"}'
```

#### 2.2 User Service ë¶„ë¦¬ (3ì£¼)

**ë³µì¡ë„**: ì¤‘ê°„ (ë§ì€ ì„œë¹„ìŠ¤ê°€ ì‚¬ìš©ì ì •ë³´ í•„ìš”)

**ì „ëµ**: API ê²Œì´íŠ¸ì›¨ì´ì—ì„œ ì¸ì¦ ì²˜ë¦¬ + ìºì‹±

```python
# services/user-service/main.py
from fastapi import FastAPI, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from passlib.hash import bcrypt

app = FastAPI(title="User & Account Service")

@app.post("/api/users/login")
async def login(username: str, password: str, db: AsyncSession = Depends(get_db)):
    user = await db.execute(
        "SELECT * FROM users WHERE username = ?", username
    )
    if not user or not bcrypt.verify(password, user.password_hash):
        raise HTTPException(status_code=401, detail="Invalid credentials")

    # JWT í† í° ìƒì„±
    token = create_jwt_token(user.user_id)
    return {"access_token": token, "user_id": user.user_id}

@app.get("/api/users/{user_id}")
async def get_user(user_id: str, db: AsyncSession = Depends(get_db)):
    user = await db.execute(
        "SELECT user_id, username, email, created_at FROM users WHERE user_id = ?",
        user_id
    )
    if not user:
        raise HTTPException(status_code=404)
    return user
```

**API Gatewayì—ì„œ ì¸ì¦ ì²˜ë¦¬**:
```lua
-- Kong Lua í”ŒëŸ¬ê·¸ì¸
local jwt = require "kong.plugins.jwt.jwt_parser"

function kong.access()
  local token = kong.request.get_header("Authorization")
  local jwt_token = jwt:new(token)

  if not jwt_token:verify() then
    kong.response.exit(401, {message = "Unauthorized"})
  end

  -- ì‚¬ìš©ì ì •ë³´ë¥¼ í—¤ë”ì— ì¶”ê°€ (ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì„œë¹„ìŠ¤ ì „ë‹¬)
  kong.service.request.set_header("X-User-ID", jwt_token.claims.user_id)
end
```

---

### 5.4 Phase 3-5: í•µì‹¬ ì„œë¹„ìŠ¤ ë¶„ë¦¬ (5ê°œì›”)

ê° ì„œë¹„ìŠ¤ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸:

```markdown
## Market Data Service ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] WebSocket ì—°ê²° ê´€ë¦¬ ì½”ë“œ ì¶”ì¶œ
- [ ] Redis Streams ì´ë²¤íŠ¸ ë°œí–‰ êµ¬í˜„
- [ ] REST API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ (ticker, orderbook, candles)
- [ ] Dockerfile ë° Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì‘ì„±
- [ ] ê¸°ì¡´ ì½”ë“œì—ì„œ API í˜¸ì¶œë¡œ ë³€ê²½
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì§€ì—° ì‹œê°„ ì¸¡ì •)
- [ ] ì¹´ë‚˜ë¦¬ ë°°í¬ (10% â†’ 50% â†’ 100%)
- [ ] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
- [ ] ê¸°ì¡´ ì½”ë“œ ì œê±°

## OMS ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì£¼ë¬¸ CRUD API êµ¬í˜„
- [ ] Saga íŒ¨í„´ êµ¬í˜„ (ë¶„ì‚° íŠ¸ëœì­ì…˜)
- [ ] Exchange Gateway í†µí•©
- [ ] Position Service í†µí•©
- [ ] WebSocket ì´ë²¤íŠ¸ ì†Œë¹„ (ì²´ê²° ì•Œë¦¼)
- [ ] PostgreSQL ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] Redis í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¶„ë¦¬
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ (ì£¼ë¬¸ ì „ì²´ í”Œë¡œìš°)
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ (TPS ì¸¡ì •)
- [ ] ë°°í¬ ë° ê²€ì¦
```

---

### 5.5 ë¦¬ìŠ¤í¬ ì™„í™” ì „ëµ

#### A. Feature Flags

```python
from typing import Any
import redis.asyncio as aioredis

class FeatureFlagManager:
    def __init__(self):
        self.redis = aioredis.from_url("redis://localhost:6379")

    async def is_enabled(self, flag_name: str, user_id: str = None) -> bool:
        # ê¸€ë¡œë²Œ í”Œë˜ê·¸ í™•ì¸
        global_flag = await self.redis.get(f"feature:{flag_name}:enabled")
        if global_flag == "false":
            return False

        # ì‚¬ìš©ìë³„ í”Œë˜ê·¸ í™•ì¸ (A/B í…ŒìŠ¤íŠ¸)
        if user_id:
            user_flag = await self.redis.get(f"feature:{flag_name}:user:{user_id}")
            if user_flag is not None:
                return user_flag == "true"

        # ë¡¤ì•„ì›ƒ ë¹„ìœ¨ í™•ì¸
        rollout = await self.redis.get(f"feature:{flag_name}:rollout")
        if rollout:
            return hash(user_id or "") % 100 < int(rollout)

        return True

# ì‚¬ìš© ì˜ˆì‹œ
ff = FeatureFlagManager()

async def create_order(user_id: str, ...):
    if await ff.is_enabled("use_new_oms", user_id):
        # ìƒˆ OMS ì„œë¹„ìŠ¤ í˜¸ì¶œ
        return await new_oms_client.create_order(...)
    else:
        # ê¸°ì¡´ ëª¨ë…¸ë¦¬ìŠ¤ ë¡œì§
        return await legacy_create_order(...)
```

#### B. Canary Deployment

```yaml
# Kubernetes Canary Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oms-service-stable
spec:
  replicas: 9  # 90% íŠ¸ë˜í”½
  selector:
    matchLabels:
      app: oms-service
      version: stable
  template:
    metadata:
      labels:
        app: oms-service
        version: stable
    spec:
      containers:
      - name: oms
        image: oms-service:v1.0.0
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oms-service-canary
spec:
  replicas: 1  # 10% íŠ¸ë˜í”½
  selector:
    matchLabels:
      app: oms-service
      version: canary
  template:
    metadata:
      labels:
        app: oms-service
        version: canary
    spec:
      containers:
      - name: oms
        image: oms-service:v2.0.0-canary
```

#### C. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ (Dual Write)

```python
# Phase 1: Dual Write (ëª¨ë…¸ë¦¬ìŠ¤ + ìƒˆ ì„œë¹„ìŠ¤ ëª¨ë‘ ì“°ê¸°)
async def create_order_dual_write(user_id: str, ...):
    # ê¸°ì¡´ DBì— ì“°ê¸°
    legacy_order_id = await legacy_db.execute("INSERT INTO orders ...")

    # ìƒˆ ì„œë¹„ìŠ¤ DBì—ë„ ì“°ê¸°
    try:
        new_order_id = await new_oms_db.execute("INSERT INTO oms.orders ...")
    except Exception as e:
        logger.error(f"New OMS write failed: {e}")
        # ê³„ì† ì§„í–‰ (ê¸°ì¡´ DBê°€ source of truth)

    return legacy_order_id

# Phase 2: Read from New (ìƒˆ ì„œë¹„ìŠ¤ì—ì„œ ì½ê¸°, ì—†ìœ¼ë©´ fallback)
async def get_order(order_id: str):
    order = await new_oms_db.fetch_one("SELECT * FROM oms.orders WHERE order_id = ?", order_id)
    if not order:
        # Fallback to legacy
        order = await legacy_db.fetch_one("SELECT * FROM orders WHERE order_id = ?", order_id)
    return order

# Phase 3: Switch (ìƒˆ ì„œë¹„ìŠ¤ê°€ source of truth)
# Phase 4: Remove Legacy (ê¸°ì¡´ ì½”ë“œ ì œê±°)
```

---

### 5.6 í…ŒìŠ¤íŠ¸ ì „ëµ

#### A. Contract Testing (Pact)

```python
# OMS Service Contract (Provider)
from pact import Provider

provider = Provider('oms-service')

@provider.given('an order exists')
async def order_exists():
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    await db.execute("INSERT INTO orders VALUES ('test-order-123', ...)")

@provider.upon_receiving('a request to get order')
async def get_order_contract():
    # ì‹¤ì œ API í˜¸ì¶œ
    response = await client.get('/api/orders/test-order-123')
    assert response.status_code == 200
    assert response.json()['order_id'] == 'test-order-123'

# HYPERRSI Service (Consumer)
from pact import Consumer

consumer = Consumer('hyperrsi-service')
pact = consumer.has_pact_with(Provider('oms-service'))

@pact.given('an order exists')
@pact.upon_receiving('a request to get order')
async def test_get_order():
    # Contract ì •ì˜
    pact.with_request(
        method='GET',
        path='/api/orders/test-order-123'
    ).will_respond_with(
        status=200,
        body={'order_id': 'test-order-123', 'status': 'filled'}
    )

    # ì‹¤ì œ ì½”ë“œ í…ŒìŠ¤íŠ¸
    order = await oms_client.get_order('test-order-123')
    assert order['status'] == 'filled'
```

#### B. Integration Testing

```python
import pytest
from testcontainers.postgres import PostgresContainer
from testcontainers.redis import RedisContainer

@pytest.fixture(scope="session")
async def test_infrastructure():
    # PostgreSQL ì»¨í…Œì´ë„ˆ
    postgres = PostgresContainer("postgres:15")
    postgres.start()

    # Redis ì»¨í…Œì´ë„ˆ
    redis = RedisContainer("redis:7")
    redis.start()

    yield {
        "postgres_url": postgres.get_connection_url(),
        "redis_url": redis.get_connection_url()
    }

    postgres.stop()
    redis.stop()

@pytest.mark.asyncio
async def test_order_creation_flow(test_infrastructure):
    # ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸: HYPERRSI â†’ OMS â†’ Exchange Gateway â†’ Position

    # 1. ì „ëµì—ì„œ ì£¼ë¬¸ ìƒì„± ìš”ì²­
    response = await hyperrsi_client.post("/api/strategy/hyperrsi/create_order", json={
        "user_id": "test-user",
        "symbol": "BTC-USDT-SWAP",
        "side": "buy",
        "quantity": 0.1
    })
    assert response.status_code == 201
    order_id = response.json()["order_id"]

    # 2. OMSì—ì„œ ì£¼ë¬¸ ìƒíƒœ í™•ì¸
    order = await oms_client.get(f"/api/orders/{order_id}")
    assert order["status"] == "pending"

    # 3. ì²´ê²° ì´ë²¤íŠ¸ ë°œí–‰ (ì‹œë®¬ë ˆì´ì…˜)
    await redis_client.xadd("events:order_filled", {
        "order_id": order_id,
        "filled_qty": 0.1,
        "fill_price": 50000
    })

    # 4. Position Serviceì—ì„œ í¬ì§€ì…˜ ì—…ë°ì´íŠ¸ í™•ì¸
    await asyncio.sleep(1)  # ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸°
    position = await position_client.get(f"/api/positions/test-user/BTC-USDT-SWAP")
    assert position["quantity"] == 0.1
```

---

## 6. ë¹„ë™ê¸° ì•„í‚¤í…ì²˜ íŒ¨í„´

### 6.1 Python 3.12+ ë¹„ë™ê¸° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

#### A. asyncio.TaskGroup (Python 3.11+)

```python
import asyncio
from typing import List

# Before: asyncio.gather (ì—ëŸ¬ ì²˜ë¦¬ ì–´ë ¤ì›€)
async def fetch_all_tickers_old(symbols: List[str]):
    tasks = [fetch_ticker(symbol) for symbol in symbols]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    # ì—ëŸ¬ ê°œë³„ ì²˜ë¦¬ ë³µì¡
    return results

# After: TaskGroup (êµ¬ì¡°í™”ëœ ì—ëŸ¬ ì²˜ë¦¬)
async def fetch_all_tickers(symbols: List[str]):
    async with asyncio.TaskGroup() as tg:
        tasks = [tg.create_task(fetch_ticker(symbol)) for symbol in symbols]

    # ëª¨ë“  íƒœìŠ¤í¬ ì„±ê³µ ë˜ëŠ” í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨ ì‹œ ExceptionGroup ë°œìƒ
    results = [task.result() for task in tasks]
    return results

# ExceptionGroup ì²˜ë¦¬
try:
    tickers = await fetch_all_tickers(["BTC-USDT", "ETH-USDT"])
except* asyncio.CancelledError as eg:
    # ì·¨ì†Œëœ íƒœìŠ¤í¬ë§Œ ì²˜ë¦¬
    logger.warning(f"Cancelled tasks: {eg.exceptions}")
except* Exception as eg:
    # ê¸°íƒ€ ì—ëŸ¬ ì²˜ë¦¬
    logger.error(f"Errors: {eg.exceptions}")
```

#### B. Async Context Managers

```python
from contextlib import asynccontextmanager
from typing import AsyncGenerator
import redis.asyncio as aioredis

@asynccontextmanager
async def get_redis_connection() -> AsyncGenerator[aioredis.Redis, None]:
    """Redis ì—°ê²° ìë™ ê´€ë¦¬"""
    client = await aioredis.from_url("redis://localhost:6379")
    try:
        yield client
    finally:
        await client.close()

# ì‚¬ìš©
async def set_user_status(user_id: str, status: str):
    async with get_redis_connection() as redis:
        await redis.setex(f"user:{user_id}:status", 3600, status)
```

#### C. Async Generators & Streaming

```python
from typing import AsyncGenerator

async def stream_market_data(symbol: str) -> AsyncGenerator[dict, None]:
    """ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°"""
    async with aioredis.from_url("redis://localhost:6379") as redis:
        last_id = '0-0'

        while True:
            # Redis Streamsì—ì„œ ì½ê¸°
            events = await redis.xread(
                {f"market:{symbol}:ticks": last_id},
                count=10,
                block=1000
            )

            for stream, messages in events:
                for message_id, data in messages:
                    yield data
                    last_id = message_id

# FastAPIì—ì„œ ì‚¬ìš© (Server-Sent Events)
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

@app.get("/api/market/stream/{symbol}")
async def stream_ticker(symbol: str):
    async def event_generator():
        async for data in stream_market_data(symbol):
            yield f"data: {json.dumps(data)}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

---

### 6.2 FastAPI ë¹„ë™ê¸° íŒ¨í„´

#### A. ì˜ì¡´ì„± ì£¼ì… (Async Dependencies)

```python
from fastapi import Depends, FastAPI
from sqlalchemy.ext.asyncio import AsyncSession
import redis.asyncio as aioredis

app = FastAPI()

# ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì˜ì¡´ì„±
async def get_db() -> AsyncGenerator[AsyncSession, None]:
    async with async_session_maker() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise

# Redis í´ë¼ì´ì–¸íŠ¸ ì˜ì¡´ì„±
async def get_redis() -> aioredis.Redis:
    return await aioredis.from_url("redis://localhost:6379")

# ì‚¬ìš©ì ì¸ì¦ ì˜ì¡´ì„±
async def get_current_user(
    user_id: str = Header(...),
    db: AsyncSession = Depends(get_db)
) -> User:
    user = await db.execute(
        select(User).where(User.user_id == user_id)
    )
    if not user:
        raise HTTPException(status_code=401)
    return user

# ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì‚¬ìš©
@app.post("/api/orders/create")
async def create_order(
    order: OrderCreate,
    user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
    redis: aioredis.Redis = Depends(get_redis)
):
    # ì˜ì¡´ì„± ìë™ ì£¼ì…
    pass
```

#### B. Background Tasks

```python
from fastapi import BackgroundTasks

async def send_notification_async(user_id: str, message: str):
    """ë¹„ë™ê¸° ì•Œë¦¼ ì „ì†¡ (FastAPI ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬)"""
    async with httpx.AsyncClient() as client:
        await client.post(
            "http://notification-service:8007/api/notifications/send",
            json={"user_id": user_id, "message": message}
        )

@app.post("/api/orders/create")
async def create_order(
    order: OrderCreate,
    background_tasks: BackgroundTasks,
    user: User = Depends(get_current_user)
):
    # ì£¼ë¬¸ ìƒì„±
    order_id = await oms_client.create_order(...)

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì•Œë¦¼ ì „ì†¡ (ì‘ë‹µ ì§€ì—° ì—†ìŒ)
    background_tasks.add_task(
        send_notification_async,
        user.user_id,
        f"ì£¼ë¬¸ ìƒì„±: {order_id}"
    )

    return {"order_id": order_id}
```

#### C. Lifespan Events

```python
from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ
    await init_db()
    await init_redis()
    await start_websocket_manager()

    yield

    # ì¢…ë£Œ ì‹œ
    await close_db()
    await close_redis()
    await stop_websocket_manager()

app = FastAPI(lifespan=lifespan)
```

---

### 6.3 Redis ë¹„ë™ê¸° íŒ¨í„´

#### A. Connection Pooling

```python
from redis.asyncio import ConnectionPool, Redis
from typing import Optional

class RedisManager:
    _pool: Optional[ConnectionPool] = None

    @classmethod
    async def get_pool(cls) -> ConnectionPool:
        if cls._pool is None:
            cls._pool = ConnectionPool.from_url(
                "redis://localhost:6379",
                max_connections=100,
                decode_responses=True
            )
        return cls._pool

    @classmethod
    async def get_client(cls) -> Redis:
        pool = await cls.get_pool()
        return Redis(connection_pool=pool)

# ì‚¬ìš©
async def set_value(key: str, value: str):
    redis = await RedisManager.get_client()
    await redis.set(key, value)
```

#### B. Pipeline (ë°°ì¹˜ ì‘ì—…)

```python
async def update_multiple_positions(positions: List[Position]):
    redis = await RedisManager.get_client()

    async with redis.pipeline(transaction=True) as pipe:
        for pos in positions:
            key = f"position:{pos.user_id}:{pos.symbol}"
            pipe.hset(key, mapping={
                "quantity": pos.quantity,
                "avg_price": pos.avg_price,
                "pnl": pos.pnl
            })
            pipe.expire(key, 3600)

        # í•œ ë²ˆì— ì‹¤í–‰ (ë„¤íŠ¸ì›Œí¬ ì™•ë³µ ìµœì†Œí™”)
        await pipe.execute()
```

#### C. Pub/Sub íŒ¨í„´

```python
import asyncio

async def publish_price_update(symbol: str, price: float):
    redis = await RedisManager.get_client()
    await redis.publish(f"price:{symbol}", json.dumps({"price": price}))

async def subscribe_to_prices(symbols: List[str]):
    redis = await RedisManager.get_client()
    pubsub = redis.pubsub()

    # ì±„ë„ êµ¬ë…
    await pubsub.subscribe(*[f"price:{s}" for s in symbols])

    try:
        async for message in pubsub.listen():
            if message['type'] == 'message':
                data = json.loads(message['data'])
                await handle_price_update(message['channel'], data)
    finally:
        await pubsub.unsubscribe()
```

---

### 6.4 Celery ëŒ€ì•ˆ: Dramatiq + asyncio

**ë¬¸ì œ**: CeleryëŠ” asyncio ë„¤ì´í‹°ë¸Œ ì§€ì› ì•½í•¨

**ëŒ€ì•ˆ**: Dramatiq (async ì‘ì—… í)

```python
import dramatiq
from dramatiq.brokers.redis import RedisBroker
from dramatiq.middleware import AsyncIO

# Broker ì„¤ì •
redis_broker = RedisBroker(url="redis://localhost:6379")
redis_broker.add_middleware(AsyncIO())
dramatiq.set_broker(redis_broker)

# ë¹„ë™ê¸° ì‘ì—… ì •ì˜
@dramatiq.actor(max_retries=3, time_limit=60000)
async def process_order_async(order_id: str):
    async with get_db() as db:
        order = await db.fetch_one("SELECT * FROM orders WHERE order_id = ?", order_id)

        # ê±°ë˜ì†Œì— ì£¼ë¬¸ ì œì¶œ
        result = await exchange_client.submit_order(order)

        # ê²°ê³¼ ì €ì¥
        await db.execute(
            "UPDATE orders SET status = ?, exchange_order_id = ? WHERE order_id = ?",
            result['status'], result['exchange_order_id'], order_id
        )

# ì‘ì—… íì— ì¶”ê°€
await process_order_async.send(order_id="order-123")
```

**ì¥ì **:
- ë„¤ì´í‹°ë¸Œ asyncio ì§€ì›
- ê°„ë‹¨í•œ API
- ë¹ ë¥¸ ì„±ëŠ¥

**ë‹¨ì **:
- Celery ëŒ€ë¹„ ìƒíƒœê³„ ì‘ìŒ
- ë§ˆì´ê·¸ë ˆì´ì…˜ ë¹„ìš©

---

### 6.5 ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜

#### Event Bus êµ¬í˜„ (Redis Streams ê¸°ë°˜)

```python
from typing import Callable, Dict, List
import asyncio

class EventBus:
    def __init__(self):
        self.redis = None
        self.handlers: Dict[str, List[Callable]] = {}

    async def connect(self):
        self.redis = await aioredis.from_url("redis://localhost:6379")

    async def publish(self, event_type: str, data: dict):
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        await self.redis.xadd(
            f"events:{event_type}",
            {"data": json.dumps(data), "timestamp": time.time()}
        )

    def subscribe(self, event_type: str, handler: Callable):
        """ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡"""
        if event_type not in self.handlers:
            self.handlers[event_type] = []
        self.handlers[event_type].append(handler)

    async def start_consuming(self):
        """ì´ë²¤íŠ¸ ì†Œë¹„ ì‹œì‘"""
        last_ids = {f"events:{et}": '0-0' for et in self.handlers.keys()}

        while True:
            events = await self.redis.xread(last_ids, count=10, block=1000)

            for stream, messages in events:
                event_type = stream.decode().split(':')[1]

                for message_id, fields in messages:
                    data = json.loads(fields[b'data'])

                    # ëª¨ë“  í•¸ë“¤ëŸ¬ ì‹¤í–‰
                    for handler in self.handlers.get(event_type, []):
                        try:
                            await handler(data)
                        except Exception as e:
                            logger.error(f"Handler error: {e}")

                    last_ids[stream] = message_id

# ì‚¬ìš© ì˜ˆì‹œ
event_bus = EventBus()
await event_bus.connect()

# í•¸ë“¤ëŸ¬ ë“±ë¡
@event_bus.subscribe("order.filled")
async def handle_order_filled(data: dict):
    # í¬ì§€ì…˜ ì—…ë°ì´íŠ¸
    await position_service.update_position(data['user_id'], data['symbol'], data['filled_qty'])

@event_bus.subscribe("order.filled")
async def send_fill_notification(data: dict):
    # ì•Œë¦¼ ì „ì†¡
    await notification_service.send(data['user_id'], f"ì£¼ë¬¸ ì²´ê²°: {data['order_id']}")

# ì´ë²¤íŠ¸ ë°œí–‰
await event_bus.publish("order.filled", {
    "order_id": "order-123",
    "user_id": "user-456",
    "symbol": "BTC-USDT-SWAP",
    "filled_qty": 0.1,
    "fill_price": 50000
})

# ì´ë²¤íŠ¸ ì†Œë¹„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
asyncio.create_task(event_bus.start_consuming())
```

---

## 7. ìš´ì˜ ê³ ë ¤ì‚¬í•­

### 7.1 ëª¨ë‹ˆí„°ë§ ë° Observability

#### A. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (Prometheus)

```python
from prometheus_client import Counter, Histogram, Gauge
from fastapi import FastAPI
from prometheus_fastapi_instrumentator import Instrumentator

app = FastAPI()

# ë©”íŠ¸ë¦­ ì •ì˜
order_created_counter = Counter(
    'orders_created_total',
    'Total number of orders created',
    ['exchange', 'symbol', 'side']
)

order_latency_histogram = Histogram(
    'order_creation_latency_seconds',
    'Order creation latency',
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0]
)

active_positions_gauge = Gauge(
    'active_positions',
    'Number of active positions',
    ['exchange', 'symbol']
)

# FastAPI ìë™ ê³„ì¸¡
Instrumentator().instrument(app).expose(app)

# ìˆ˜ë™ ë©”íŠ¸ë¦­ ê¸°ë¡
@app.post("/api/orders/create")
async def create_order(order: OrderCreate):
    with order_latency_histogram.time():
        result = await oms_client.create_order(...)

        order_created_counter.labels(
            exchange=order.exchange,
            symbol=order.symbol,
            side=order.side
        ).inc()

    return result
```

#### B. ë¶„ì‚° ì¶”ì  (OpenTelemetry)

```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor

# Tracer ì„¤ì •
tracer_provider = TracerProvider()
jaeger_exporter = JaegerExporter(
    agent_host_name="jaeger",
    agent_port=6831,
)
tracer_provider.add_span_processor(BatchSpanProcessor(jaeger_exporter))
trace.set_tracer_provider(tracer_provider)

# FastAPI ìë™ ê³„ì¸¡
FastAPIInstrumentor.instrument_app(app)
HTTPXClientInstrumentor().instrument()

# ìˆ˜ë™ span ìƒì„±
tracer = trace.get_tracer(__name__)

@app.post("/api/orders/create")
async def create_order(order: OrderCreate):
    with tracer.start_as_current_span("create_order") as span:
        span.set_attribute("order.symbol", order.symbol)
        span.set_attribute("order.side", order.side)

        # 1. ì”ê³  í™•ì¸
        with tracer.start_as_current_span("check_balance"):
            balance = await exchange_gateway.get_balance(order.user_id)

        # 2. ì£¼ë¬¸ ìƒì„±
        with tracer.start_as_current_span("submit_order"):
            result = await oms_client.create_order(...)

        return result
```

#### C. êµ¬ì¡°í™”ëœ ë¡œê¹… (JSON Logs)

```python
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "service": "hyperrsi-service",
            "message": record.getMessage(),
            "logger": record.name,
        }

        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
        if hasattr(record, 'order_id'):
            log_data['order_id'] = record.order_id
        if hasattr(record, 'trace_id'):
            log_data['trace_id'] = record.trace_id

        return json.dumps(log_data)

# ë¡œê±° ì„¤ì •
logger = logging.getLogger("hyperrsi")
handler = logging.StreamHandler()
handler.setFormatter(JSONFormatter())
logger.addHandler(handler)

# ì‚¬ìš©
logger.info(
    "Order created",
    extra={"user_id": "user-123", "order_id": "order-456", "symbol": "BTC-USDT"}
)
```

---

### 7.2 ë°°í¬ ì „ëµ (Kubernetes)

#### A. Deployment ë§¤ë‹ˆí˜ìŠ¤íŠ¸

```yaml
# services/hyperrsi/k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hyperrsi-service
  labels:
    app: hyperrsi-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hyperrsi-service
  template:
    metadata:
      labels:
        app: hyperrsi-service
    spec:
      containers:
      - name: hyperrsi
        image: hyperrsi-service:v1.0.0
        ports:
        - containerPort: 8001
        env:
        - name: REDIS_HOST
          value: "redis-cluster"
        - name: REDIS_PORT
          value: "6379"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8001
          initialDelaySeconds: 10
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: hyperrsi-service
spec:
  selector:
    app: hyperrsi-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8001
  type: ClusterIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hyperrsi-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: hyperrsi-service
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

#### B. ConfigMap & Secrets

```yaml
# ConfigMap (í™˜ê²½ë³€ìˆ˜)
apiVersion: v1
kind: ConfigMap
metadata:
  name: hyperrsi-config
data:
  ENVIRONMENT: "production"
  LOG_LEVEL: "INFO"
  REDIS_HOST: "redis-cluster"
  REDIS_PORT: "6379"
---
# Secret (ë¯¼ê° ì •ë³´)
apiVersion: v1
kind: Secret
metadata:
  name: hyperrsi-secrets
type: Opaque
stringData:
  OKX_API_KEY: "your-api-key"
  OKX_SECRET_KEY: "your-secret-key"
  OKX_PASSPHRASE: "your-passphrase"
  DATABASE_URL: "postgresql://user:pass@postgres:5432/tradingboost"
```

#### C. Helm Chart êµ¬ì¡°

```
charts/hyperrsi-service/
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ values.yaml
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ hpa.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â””â”€â”€ secret.yaml
â””â”€â”€ values/
    â”œâ”€â”€ production.yaml
    â””â”€â”€ staging.yaml
```

---

### 7.3 ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

#### A. API í‚¤ ì•”í˜¸í™” ì €ì¥

```python
from cryptography.fernet import Fernet
import base64
import os

class CredentialManager:
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì•”í˜¸í™” í‚¤ ë¡œë“œ
        key = os.getenv("ENCRYPTION_KEY").encode()
        self.cipher = Fernet(key)

    def encrypt(self, plaintext: str) -> str:
        """API í‚¤ ì•”í˜¸í™”"""
        encrypted = self.cipher.encrypt(plaintext.encode())
        return base64.b64encode(encrypted).decode()

    def decrypt(self, encrypted: str) -> str:
        """API í‚¤ ë³µí˜¸í™”"""
        decoded = base64.b64decode(encrypted.encode())
        decrypted = self.cipher.decrypt(decoded)
        return decrypted.decode()

# DBì— ì•”í˜¸í™”ëœ í‚¤ ì €ì¥
cm = CredentialManager()
encrypted_api_key = cm.encrypt(user_api_key)
await db.execute(
    "INSERT INTO user_credentials (user_id, api_key_encrypted) VALUES (?, ?)",
    user_id, encrypted_api_key
)

# ì‚¬ìš© ì‹œ ë³µí˜¸í™”
encrypted = await db.fetch_one("SELECT api_key_encrypted FROM user_credentials WHERE user_id = ?", user_id)
api_key = cm.decrypt(encrypted['api_key_encrypted'])
```

#### B. Rate Limiting (API Gateway)

```python
# Kong Rate Limiting í”ŒëŸ¬ê·¸ì¸
curl -X POST http://kong:8001/services/hyperrsi-service/plugins \
  --data "name=rate-limiting" \
  --data "config.second=10" \
  --data "config.minute=100" \
  --data "config.hour=1000" \
  --data "config.policy=redis" \
  --data "config.redis_host=redis" \
  --data "config.redis_port=6379"
```

#### C. ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ (Service Mesh)

```yaml
# Istio VirtualService (ì„œë¹„ìŠ¤ ê°„ í†µì‹  ì œì–´)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: oms-service
spec:
  hosts:
  - oms-service
  http:
  - match:
    - sourceLabels:
        app: hyperrsi-service
    - sourceLabels:
        app: grid-service
    route:
    - destination:
        host: oms-service
        port:
          number: 8004
  - route:
    - destination:
        host: access-denied  # ë‹¤ë¥¸ ì„œë¹„ìŠ¤ëŠ” ì ‘ê·¼ ê±°ë¶€
```

---

### 7.4 ì„±ëŠ¥ ìµœì í™”

#### A. Connection Pooling

```python
# PostgreSQL ì—°ê²° í’€ ì„¤ì •
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,           # ê¸°ë³¸ ì—°ê²° ìˆ˜
    max_overflow=10,        # ì¶”ê°€ ì—°ê²° ìˆ˜
    pool_timeout=30,        # ì—°ê²° ëŒ€ê¸° ì‹œê°„
    pool_recycle=3600,      # ì—°ê²° ì¬í™œìš© ì£¼ê¸°
    pool_pre_ping=True,     # ì—°ê²° ìœ íš¨ì„± ê²€ì‚¬
    echo=False
)

async_session_maker = sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False
)
```

#### B. ìºì‹œ ì „ëµ

```python
from functools import wraps
import hashlib

def cache_result(ttl: int = 60):
    """í•¨ìˆ˜ ê²°ê³¼ ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}:{hashlib.md5(str(args).encode() + str(kwargs).encode()).hexdigest()}"

            # ìºì‹œ í™•ì¸
            redis = await RedisManager.get_client()
            cached = await redis.get(cache_key)
            if cached:
                return json.loads(cached)

            # í•¨ìˆ˜ ì‹¤í–‰
            result = await func(*args, **kwargs)

            # ê²°ê³¼ ìºì‹±
            await redis.setex(cache_key, ttl, json.dumps(result))
            return result

        return wrapper
    return decorator

# ì‚¬ìš©
@cache_result(ttl=300)  # 5ë¶„ ìºì‹±
async def get_market_info(exchange: str, symbol: str):
    # ê±°ë˜ì†Œ API í˜¸ì¶œ (ëŠë¦¼)
    return await exchange_client.get_market_info(exchange, symbol)
```

#### C. ë°°ì¹˜ ì²˜ë¦¬

```python
from typing import List

async def batch_create_orders(orders: List[OrderCreate]) -> List[str]:
    """ì—¬ëŸ¬ ì£¼ë¬¸ ë°°ì¹˜ ìƒì„±"""
    async with asyncio.TaskGroup() as tg:
        tasks = [tg.create_task(create_order(order)) for order in orders]

    return [task.result()['order_id'] for task in tasks]

# ê±°ë˜ì†Œ API ë°°ì¹˜ í˜¸ì¶œ
async def batch_get_balances(user_ids: List[str]) -> Dict[str, dict]:
    """ì—¬ëŸ¬ ì‚¬ìš©ì ì”ê³  ë°°ì¹˜ ì¡°íšŒ"""
    async with httpx.AsyncClient() as client:
        # ë™ì‹œ ìš”ì²­ (ìµœëŒ€ 10ê°œ)
        semaphore = asyncio.Semaphore(10)

        async def get_balance(user_id: str):
            async with semaphore:
                response = await client.get(f"/api/exchange/balance/{user_id}")
                return user_id, response.json()

        results = await asyncio.gather(*[get_balance(uid) for uid in user_ids])
        return dict(results)
```

---

## 8. ìµœì¢… ê¶Œì¥ì‚¬í•­

### 8.1 Go/No-Go ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤

| ê¸°ì¤€ | í˜„ì¬ ìƒíƒœ | ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í•„ìš”ì„± | ì ìˆ˜ (1-5) |
|------|----------|---------------------|-----------|
| **íŒ€ ê·œëª¨** | 2-5ëª… | 10ëª…+ ì‹œ ìµœì  | 2/5 |
| **ì„œë¹„ìŠ¤ ë³µì¡ë„** | ì¤‘ê°„ (2ê°œ ì „ëµ) | 5ê°œ+ ì „ëµ ì‹œ ìµœì  | 3/5 |
| **ë°°í¬ ë¹ˆë„** | ì£¼ 1íšŒ | ì¼ 1íšŒ+ ì‹œ ìµœì  | 2/5 |
| **ìŠ¤ì¼€ì¼ë§ ìš”êµ¬** | ìœ ì € 100ëª… ì´í•˜ | 1000ëª…+ ì‹œ í•„ìš” | 2/5 |
| **ê¸°ìˆ  ë‹¤ì–‘ì„±** | Python ë‹¨ì¼ | ë‹¤ì¤‘ ì–¸ì–´ ì‹œ ìœ ë¦¬ | 1/5 |
| **ì¥ì•  ê²©ë¦¬** | ì¤‘ìš” (ê±°ë˜ ì‹œìŠ¤í…œ) | ë§¤ìš° ì¤‘ìš” | 5/5 |
| **ìš´ì˜ ì—­ëŸ‰** | ê¸°ë³¸ (Docker) | ê³ ê¸‰ (K8s) í•„ìš” | 2/5 |

**ì´ì **: 17/35 (48%)

---

### 8.2 ê¶Œì¥ì‚¬í•­

#### ğŸŸ¢ **ë‹¨ê¸° (3-6ê°œì›”): Modular Monolith ì ‘ê·¼**

**í˜„ ìƒíƒœì—ì„œëŠ” ì™„ì „í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì „í™˜ì´ ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§ì…ë‹ˆë‹¤.**

**ëŒ€ì‹  ë‹¤ìŒì„ ì¶”ì²œ**:

1. **Shared ëª¨ë“ˆ ê°œì„ **
   - ëª…í™•í•œ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
   - ì˜ì¡´ì„± ì—­ì „ ì›ì¹™ ì ìš©
   - ë²„ì „ ê´€ë¦¬ ë„ì…

2. **ì„œë¹„ìŠ¤ ê²½ê³„ ì„¤ê³„**
   - ê° ì „ëµì„ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ êµ¬ì¡°í™”
   - API ê³„ì•½ ëª…ì‹œ (OpenAPI)
   - ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë¶„ë¦¬ (ìŠ¤í‚¤ë§ˆ ë ˆë²¨)

3. **ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  ë„ì…**
   - Redis Streamsë¡œ ëŠìŠ¨í•œ ê²°í•©
   - ì£¼ë¬¸/í¬ì§€ì…˜ ì—…ë°ì´íŠ¸ ì´ë²¤íŠ¸í™”

4. **ì¸í”„ë¼ ê°œì„ **
   - Redis Sentinel ê³ ê°€ìš©ì„±
   - PostgreSQL Read Replica
   - Docker Compose ê¸°ë°˜ ë¡œì»¬ ê°œë°œ í™˜ê²½

**ì˜ˆì‹œ êµ¬ì¡°**:
```
TradingBoost-Strategy/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ hyperrsi/        # ë…ë¦½ì  ëª¨ë“ˆ (ì•„ì§ ëª¨ë…¸ë¦¬ìŠ¤ ë‚´)
â”‚   â”œâ”€â”€ grid/
â”‚   â”œâ”€â”€ market_data/
â”‚   â””â”€â”€ notification/
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ interfaces/      # ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ events/          # ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ utils/
â””â”€â”€ main.py              # ë‹¨ì¼ ì§„ì…ì  ìœ ì§€
```

---

#### ğŸŸ¡ **ì¤‘ê¸° (6-12ê°œì›”): Strangler Fig ì‹œì‘**

**ì¡°ê±´**: ì‚¬ìš©ì 500ëª…+ ë˜ëŠ” ì „ëµ 5ê°œ+ ì‹œ

1. **ì²« ë²ˆì§¸ ì„œë¹„ìŠ¤ ë¶„ë¦¬**
   - Notification Service (ìœ„í—˜ ë‚®ìŒ)
   - Market Data Service (ë…ë¦½ì„± ë†’ìŒ)

2. **API Gateway ë„ì…**
   - Kong ë˜ëŠ” Traefik
   - Rate limiting, ì¸ì¦

3. **ëª¨ë‹ˆí„°ë§ ê°•í™”**
   - Prometheus + Grafana
   - ë¶„ì‚° ì¶”ì  (Jaeger)

---

#### ğŸ”´ **ì¥ê¸° (12ê°œì›”+): ì™„ì „í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤**

**ì¡°ê±´**: ì‚¬ìš©ì 1000ëª…+, íŒ€ 10ëª…+, ì „ëµ 10ê°œ+

1. **ëª¨ë“  ì„œë¹„ìŠ¤ ë¶„ë¦¬**
   - 10ê°œ ë…ë¦½ ì„œë¹„ìŠ¤
   - Kubernetes ë°°í¬
   - Service Mesh (Istio)

2. **ê³ ê¸‰ íŒ¨í„´ ì ìš©**
   - CQRS (Command Query Responsibility Segregation)
   - Event Sourcing
   - Circuit Breaker

---

### 8.3 ì‹¤ìš©ì  ì²« ë‹¨ê³„ (ì§€ê¸ˆ ë‹¹ì¥ ì‹œì‘)

#### 1ì£¼ì°¨: ë¶„ì„ ë° ì„¤ê³„

```bash
# 1. ì„œë¹„ìŠ¤ ê²½ê³„ ì •ì˜ ë¬¸ì„œ ì‘ì„±
touch docs/SERVICE_BOUNDARIES.md

# 2. API ê³„ì•½ ì •ì˜ (OpenAPI)
mkdir -p api-contracts
touch api-contracts/hyperrsi.yaml
touch api-contracts/grid.yaml
touch api-contracts/market-data.yaml
```

#### 2ì£¼ì°¨: Shared ëª¨ë“ˆ ë¦¬íŒ©í„°ë§

```python
# shared/interfaces/strategy.py
from abc import ABC, abstractmethod

class StrategyInterface(ABC):
    @abstractmethod
    async def activate(self, user_id: str, symbol: str, params: dict):
        """ì „ëµ í™œì„±í™”"""
        pass

    @abstractmethod
    async def deactivate(self, user_id: str, symbol: str):
        """ì „ëµ ë¹„í™œì„±í™”"""
        pass

    @abstractmethod
    async def get_status(self, user_id: str, symbol: str) -> dict:
        """ì „ëµ ìƒíƒœ ì¡°íšŒ"""
        pass

# services/hyperrsi/strategy.py
from shared.interfaces.strategy import StrategyInterface

class HyperRSIStrategy(StrategyInterface):
    async def activate(self, user_id: str, symbol: str, params: dict):
        # êµ¬í˜„
        pass
```

#### 3-4ì£¼ì°¨: ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•

```python
# shared/events/schema.py
from pydantic import BaseModel

class OrderFilledEvent(BaseModel):
    event_type: str = "order.filled"
    order_id: str
    user_id: str
    symbol: str
    filled_qty: float
    fill_price: float

# shared/events/bus.py
# (ì•ì„œ ì •ì˜í•œ EventBus êµ¬í˜„)
```

---

### 8.4 ë¹„ìš©/ì´ìµ ë¶„ì„

| í•­ëª© | ëª¨ë…¸ë¦¬ìŠ¤ ìœ ì§€ | Modular Monolith | ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ |
|------|-------------|------------------|---------------|
| **ê°œë°œ ì†ë„** | â­â­â­â­â­ | â­â­â­â­ | â­â­ |
| **ë°°í¬ ë³µì¡ë„** | â­ | â­â­ | â­â­â­â­â­ |
| **ìš´ì˜ ë¹„ìš©** | $ | $$ | $$$$$ |
| **ìŠ¤ì¼€ì¼ë§** | â­â­ | â­â­â­ | â­â­â­â­â­ |
| **ì¥ì•  ê²©ë¦¬** | â­ | â­â­â­ | â­â­â­â­â­ |
| **íŒ€ ììœ¨ì„±** | â­ | â­â­â­ | â­â­â­â­â­ |
| **í•™ìŠµ ê³¡ì„ ** | â­ | â­â­ | â­â­â­â­â­ |

**ì¶”ì²œ**: **Modular Monolith** (ì¤‘ê°„ ì§€ì )

---

## 9. ê²°ë¡ 

### í•µì‹¬ ë©”ì‹œì§€

1. **ì§€ê¸ˆ ë‹¹ì¥ ì™„ì „í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ëŠ” í•„ìš” ì—†ìŠµë‹ˆë‹¤.**
2. **í•˜ì§€ë§Œ ë¯¸ë˜ë¥¼ ìœ„í•œ ì¤€ë¹„ëŠ” ì§€ê¸ˆ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.**
3. **Modular Monolithë¡œ ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ì „í™˜í•˜ì„¸ìš”.**

### ì‹¤í–‰ ê³„íš ìš”ì•½

```mermaid
graph LR
    A[í˜„ì¬: ëª¨ë…¸ë¦¬ìŠ¤] --> B[3ê°œì›”: Modular Monolith]
    B --> C[6ê°œì›”: API Gateway + ì²« ì„œë¹„ìŠ¤ ë¶„ë¦¬]
    C --> D[12ê°œì›”: í•µì‹¬ ì„œë¹„ìŠ¤ ë¶„ë¦¬]
    D --> E[18ê°œì›”+: ì™„ì „í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤]

    style A fill:#ff6b6b
    style B fill:#ffd93d
    style C fill:#6bcf7f
    style D fill:#4d96ff
    style E fill:#a78bfa
```

### ë‹¤ìŒ ì•¡ì…˜ ì•„ì´í…œ

- [ ] íŒ€ ë¯¸íŒ…: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì „í™˜ ë…¼ì˜
- [ ] API ê³„ì•½ ì •ì˜ ì‹œì‘
- [ ] shared ëª¨ë“ˆ ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„
- [ ] Redis Streams ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ PoC
- [ ] Docker Compose í™˜ê²½ ê°œì„ 
- [ ] ëª¨ë‹ˆí„°ë§ ê¸°ë³¸ êµ¬ì¶• (Prometheus)

---

**ë¬¸ì„œ ì‘ì„±ì**: Claude (Anthropic)
**ê²€í†  í•„ìš”**: ì•„í‚¤í…ì²˜ íŒ€, DevOps íŒ€
**ë‹¤ìŒ ì—…ë°ì´íŠ¸**: 3ê°œì›” í›„ (ì§„í–‰ ìƒí™© ë¦¬ë·°)
